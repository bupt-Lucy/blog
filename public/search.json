[{"title":"1-秒杀项目2.0-Redis机制","path":"/2025/10/05/1-秒杀项目2.0-Redis机制/","content":"突破限制：引入Redis机制当前系统V1.3 已经具备的功能： 异步处理：用户的点击会立刻得到响应。 流量控制：保护系统不会因过多线程而崩溃 原子化SQL：数据库操作精准无误 内存标记：售罄后能快速拒绝请求。 无法回避的“物理上限”： 用户体验的断崖式下跌：服务器可能在第一秒就收到了数万甚至数十万的 HTTP 请求。而应用内置的 Tomcat 服务器线程池（比如200个）会瞬间被打满。后续的所有请求，都会在操作系统的 TCP 连接队列中排队，最终大量超时。 99% 的用户刷新页面后，看到的是一个永远在“转圈圈”的加载动画，或是冰冷的 “503 Service Unavailable” 错误。 数据库是最终的性能瓶颈：数据库的磁盘IO、网络带宽、以及自身的处理能力成为了整个系统性能的天花板。 数据库通常是多个业务的共享资源。秒杀业务对数据库的极限压榨，会导致整个网站的其他核心功能全部瘫痪。普通用户无法登录、无法浏览其他商品、无法对购物车里的其他商品下单。为了一个秒杀活动，导致整个电商平台的交易系统停摆，这是任何公司都无法接受的巨大损失。 应用服务器是“单点故障”：应用运行在一个实例上，如果这个应用因为任何原因，比如JVM崩溃或服务器宕机，挂掉，那么整个秒杀服务就会彻底中断。 整个秒杀服务彻底消失，恢复时间未知。 无法水平扩展：所有基于Java内存的并发控制，在多实例部署时都会失效。 暴露了架构的僵化和脆弱 Redis能解决什么问题？ 解决了数据库雪崩和用户体验差的问题 把高频的库存读写、用户资格判断，从毫秒级的、基于磁盘的MYSQL，转移到了微秒级的、基于内存的Redis。 99%的读写流量由Redis抗住，每秒可以处理数万甚至数万次请求。 数据库只负责收尾工作，只有极少数成功抢到资格的用户，它们的订单信息才会异步的、平稳的写入数据库中。 解决了单点故障和无法水平扩展的问题 通过将所有需要共享的状态统一放在Redis中，本身的Spring Boot应用本身变成了“无状态”的。 环境准备与集成 在 Spring Boot 项目中成功引入并连接到 Redis 安装并运行Redis 在电脑上，使用docker在后台启动一个名为seckill-redis的Redis容器，并将其6379端口映射到电脑的6379端口。 docker run -d --name seckill-redis -p 6379:6379 redis 添加Maven依赖 在pom.xml文件中，添加新的依赖 dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-data-redis/artifactId/dependency 保存并让IDE重新加载依赖 配置application.properties 添加 Redis 的连接信息 # ================== Redis Configuration ==================spring.redis.host=localhostspring.redis.port=6379 验证连接 可以创建一个简单的测试类来验证应用启动时能否成功连接到Redis @Componentpublic class RedisConnectionTester implements CommandLineRunner @Autowired private StringRedisTemplate redisTemplate; @Override public void run(String... args) throws Exception try String result = redisTemplate.getConnectionFactory().getConnection().ping(); System.out.println(=========================================); System.out.println(Successfully connected to Redis. PING response: + result); System.out.println(=========================================); catch (Exception e) System.err.println(=========================================); System.err.println(Failed to connect to Redis: + e.getMessage()); System.err.println(=========================================); 启动 Spring Boot 应用。在控制台看到了 Successfully connected to Redis 的信息，表示第一阶段就成功。 数据预热与缓存“读”操作 将查询库存的流量从 MySQL 转移到 Redis。 创建数据预热Service 在秒杀开始之前，把数据从MYSQL加载到Redis。用启动时加载器来模拟。 创建RedisPreheatService.java @Servicepublic class RedisPreheatService implements CommandLineRunner public static final String STOCK_KEY = seckill:stock:; public static final String PRODUCT_KEY = seckill:product:; public static final String USER_SET_KEY = seckill:users:; @Autowired private ProductRepository productRepository; // 假设你已注入 @Autowired private RedisTemplateString, Object redisTemplate; // 应用启动后自动执行 @Override public void run(String... args) throws Exception // 假设我们秒杀的商品ID是 1 long productId = 1L; Product product = productRepository.findById(productId).orElse(null); if (product != null) // 1. 清理旧数据（为了可重复测试） redisTemplate.delete(STOCK_KEY + productId); redisTemplate.delete(USER_SET_KEY + productId); // 2. 加载库存到 Redis String redisTemplate.opsForValue().set(STOCK_KEY + productId, product.getStock()); System.out.println(=========================================); System.out.println(Product + productId + stock preheated to Redis: + product.getStock()); System.out.println(=========================================); 改造SeckillService的checkStock方法 直接从Redis读数据 // 在 SeckillService.java 中@Autowiredprivate RedisTemplateString, Object redisTemplate;public Integer checkStock(Long productId) String stockKey = RedisPreheatService.STOCK_KEY + productId; Object stockObj = redisTemplate.opsForValue().get(stockKey); return stockObj != null ? Integer.parseInt(stockObj.toString()) : -1; 核心逻辑迁移（Redis + Lua脚本） 将最关键的“判断资格扣减库存”操作，从Java层的锁+数据库，迁移到Redis的原子化Lua脚本。 创建Lua脚本文件 在 srcmainresources 目录下，创建一个新文件夹 scripts。 在 scripts 文件夹里，创建一个新文件 seckill.lua -- seckill.lua-- KEYS[1]: 库存的 key (e.g., seckill:stock:1)-- KEYS[2]: 已购买用户集合的 key (e.g., seckill:users:1)-- ARGV[1]: 当前请求的用户 ID-- 1. 判断用户是否重复购买if redis.call(sismember, KEYS[2], ARGV[1]) == 1 then return 2 -- 2 代表重复购买end-- 2. 获取库存local stock = tonumber(redis.call(get, KEYS[1]))if stock = 0 then return 1 -- 1 代表库存不足end-- 3. 扣减库存redis.call(decr, KEYS[1])-- 4. 记录购买用户redis.call(sadd, KEYS[2], ARGV[1])return 0 -- 0 代表秒杀成功 配置并加载Lua脚本 创建一个RedisConfig.java文件。用于管理与Redis相关的Bean。 @Configurationpublic class RedisConfig /** * 【新增】配置并创建 RedisTemplate Bean * @param connectionFactory Spring Boot 自动配置好的连接工厂 * @return RedisTemplate 实例 */ @Bean public RedisTemplateString, Object redisTemplate(RedisConnectionFactory connectionFactory) // 创建 RedisTemplate 对象 RedisTemplateString, Object template = new RedisTemplate(); // 设置连接工厂 template.setConnectionFactory(connectionFactory); // 创建 JSON 序列化工具 GenericJackson2JsonRedisSerializer jsonSerializer = new GenericJackson2JsonRedisSerializer(); // 设置 Key 的序列化方式为 String template.setKeySerializer(new StringRedisSerializer()); template.setHashKeySerializer(new StringRedisSerializer()); // 设置 Value 的序列化方式为 JSON template.setValueSerializer(jsonSerializer); template.setHashValueSerializer(jsonSerializer); // 使配置生效 template.afterPropertiesSet(); return template; @Bean public DefaultRedisScriptLong seckillScript() DefaultRedisScriptLong redisScript = new DefaultRedisScript(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(scripts/seckill.lua))); redisScript.setResultType(Long.class); return redisScript; 重构SeckillService的核心秒杀逻辑// 在 SeckillService.java 中@Autowiredprivate DefaultRedisScriptLong seckillScript;// 我们需要一个内存队列来存放成功秒杀的订单信息private final BlockingQueueSeckillOrder orderQueue = new LinkedBlockingQueue(1000);// 改造异步执行的后台任务private void executeSeckill(Long productId, Long userId) ListString keys = Arrays.asList( RedisPreheatService.STOCK_KEY + productId, RedisPreheatService.USER_SET_KEY + productId ); // 执行 Lua 脚本 Long result = redisTemplate.execute(seckillScript, keys, userId.toString()); if (result == 0) log.info(用户 秒杀成功！, userId); // 秒杀成功，生成订单信息并放入内存队列 // 此时订单尚未写入数据库 Product product = ... // 可以从缓存或数据库获取商品信息 SeckillOrder order = new SeckillOrder(); order.setProductId(productId); order.setUserId(userId); order.setOrderPrice(product.getPrice()); // 将订单放入队列 try orderQueue.put(order); catch (InterruptedException e) Thread.currentThread().interrupt(); else if (result == 1) log.warn(用户 秒杀失败：库存不足, userId); else if (result == 2) log.warn(用户 秒杀失败：重复下单, userId); else log.error(用户 秒杀异常, userId); 异步持久化 创建订单消费者Service 新建一个OrderConsumeService.java @Servicepublic class OrderConsumerService // ... 其他注入的属性 ... // 应用启动后，开启一个后台线程 @PostConstruct private void startConsumer() new Thread(() - while (true) try SeckillOrder order = seckillService.getOrderQueue().take(); // 2. 循环体内部现在只调用这个新的、带事务的方法 createOrderInDb(order); catch (InterruptedException e) Thread.currentThread().interrupt(); log.error(订单消费者线程被中断, e); break; catch (Exception e) // 捕获所有其他可能的异常，防止线程意外终止 log.error(处理订单时发生未知异常, e); ).start(); /** * 3. 【新增】一个公开的、带事务注解的方法，专门用于数据库操作 * @param order 从队列中取出的订单信息 */ @Transactional public void createOrderInDb(SeckillOrder order) log.info(正在创建订单并扣减MySQL库存: , order); // 将所有数据库操作都放在这个方法里 orderRepository.save(order); int result = productRepository.deductStock(order.getProductId()); if (result == 0) // 这是一个补偿逻辑，理论上在Redis阶段已经保证了库存充足 // 但为了数据最终一致性，如果MySQL库存扣减失败，应抛出异常让事务回滚 throw new RuntimeException(MySQL as stock deduction failed for order: + order); log.info(数据库订单创建成功); 在 SeckillService 中为 orderQueue 提供一个 getter 方法。 JMeter压测结果分析与改进结果分析 结果：日志显示：处理订单时发生未知异常；数据库信息显示：订单正常创建，但是库存数没有减少；存在TransactionRequiredException报错。 分析： 订单正常创建：说明 orderRepository.save(order) 这行代码执行成功了，并且它的结果被提交到了数据库。 库存数没有减少：说明 productRepository.deductStock(…) 这行代码没有成功，或者它的结果被回滚了。 存在TransactionRequiredException报错：deductStock() 在执行时，没有找到一个正在运行的事务。 即，orderRepository.save() 在一个事务里成功了（或者在没有事务的情况下自动提交了），而紧接着的 deductStock() 却发现自己不在任何事务里。但是这两个方法在同一个被@Transactional注解的方法里。所以真正的原因应该是，方法上的@Transactional注解没有生效。因为这个方法是通过this关键字进行的方法自调用，无法触发AOP代理。当startConsumer方法在 while 循环里调用 createOrderInDb(order) 时，它实际上是在调用 this.createOrderInDb(order)，绕过了AOP代理，所以无人发现@Transactional注解，事务没有被开启。 改进 注入服务自身，通过代理对象来调用方法。 修改OrderConsumerService.java @Servicepublic class OrderConsumerService // ... 其他注入的属性 ... @Autowired private SeckillService seckillService; // 2. 注入自己（代理对象） // 使用 @Lazy 是为了解决循环依赖的潜在问题 @Autowired @Lazy private OrderConsumerService self; // 应用启动后，开启一个后台线程 @PostConstruct private void startConsumer() new Thread(() - while (true) try SeckillOrder order = seckillService.getOrderQueue().take(); // 3. 【关键改动】通过 self 代理对象来调用事务方法 self.createOrderInDb(order); catch (InterruptedException e) // ... catch (Exception e) // ... ).start(); /** * 这个方法保持不变，但现在它能被正确地代理了 */ @Transactional public void createOrderInDb(SeckillOrder order) // ... 之前的数据库操作逻辑完全不变 ... log.info(正在创建订单并扣减MySQL库存: , order); orderRepository.save(order); int result = productRepository.deductStock(order.getProductId()); if (result == 0) throw new RuntimeException(MySQL stock deduction failed for order: + order); log.info(数据库订单创建成功); @Autowired private OrderConsumerService self; 注入的 self 变量，不是 this 对象，而是 Spring 创建的、包含了事务处理逻辑的代理对象。 当调用 self.createOrderInDb(order) 时，请求就从startConsumer发到了AOP代理那里。 AOP代理会正常地开启事务，然后再让真实对象去执行数据库操作。这样，@Transactional 就重新恢复了它的作用。 结果：数据库信息显示正常，库存正确减少，订单正确建立。 学学八股Redis Redis是一个开源的、基于内存的、key-value结构的高性能数据库。 基于内存：是Redis高性能的根本原因。所有数据都存储在内存中，读写速度极快，远超基于磁盘的数据库。 key-value：数据存储方式非常简单，像一个巨大的HashMap，通过一个唯一的Key来存取一个Value。 不仅仅是缓存：除了被用于缓存外，也被广泛运用于数据库、消息队列等。 核心原理（为什么快） 纯内存操作：所有的操作都在内存中完成，完全避免了磁盘IO这个最耗时的环节。 单线程模型：Redis的核心网络模型和命令处理是由一个单线程来完成的。无线程切换开销、无锁竞争、IO多路复用。 Redis的原子性与Lua脚本 Redis的单个命令是原子性的，但是多个命令组合在一起，就不是原子性的。 但Redis允许将一段Lua脚本作为一个整体发送给服务器执行，Redis会保证这个脚本在执行期间不会被任何其他命令打断，从而实现了多个命令的原子性组合。 Redis的持久化机制 RDB：在指定的时间间隔内，将内存中的数据快照完整的写入到磁盘上的一个二进制文件中。恢复速度快，文件紧凑。但如果Redis在两次快照之间崩溃，会损失一部分数据。 AOF：将每一条接受到的写命令，以追加的方式写入到一个日志文件中，恢复时，重新执行一遍文件中的所有写命令。数据的安全性更高（最多只丢失1秒的数据），单文件体积大，恢复速度相对较慢。 Redis的缓存经典问题 缓存穿透：查询一个数据库中根本不存在的数据，缓存中自然也没有，导致每次请求都直接打到数据库上，失去了缓存的意义。 缓存空对象：如果数据库查询结果为空，依然在Redis中缓存一个特殊的空值，并设置一个较短的过期时间。 布隆过滤器：在Redis前再加一道屏障，用布隆过滤器快速判断请求的数据是否存在。 缓存击穿：一个热点Key在某个瞬间突然失效，导致海量的并发请求同时涌向这个Key，并全部穿透到数据库，导致数据库瞬时压力过大。 互斥锁：当缓存失效时，第一个查询请求获取一个互斥锁，然后去加载数据并回设缓存。其他线程则等待锁释放后，直接从缓存中获取数据。 热点数据永不过期：对极热点的数据设置逻辑过期，由后台线程异步更新。 缓存雪崩：大量的key在同一时间集中失效，导致瞬时大量的请求都穿透到数据库。 随机化过期时间：在基础过期时间上，增加一个随机值，避免集中失效。 高可用架构：通过Redis集群、限流降级等操作，保证即使缓存出现问题，数据库也不会被完全冲垮。","tags":["Spring Boot","高并发","JUC"],"categories":["项目实战"]},{"title":"1-秒杀项目1.3-异步处理和优化","path":"/2025/10/03/1-秒杀项目1.3-异步处理和优化/","content":"用户体验：引入异步处理 在V1.1和V1.2，通过读写锁和信号量，构建了一个数据相对正确，流量可控的秒杀系统。尽管后端相对稳定，但用户体验糟糕，同步阻塞的模式，意味着用户必须在浏览器前“转圈圈”，等待后端的耗时操作。 在V1.3中，实现异步化，将用户请求与后端耗时任务解耦，实现用户的及时响应。 代码改写 线程池，创建ThreadPoolConfig.javaimport org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.concurrent.*;@Configurationpublic class ThreadPoolConfig @Bean public ExecutorService seckillExecutorService() // 手动实现一个简单的 ThreadFactory ThreadFactory namedThreadFactory = r - new Thread(seckill-thread- + r.hashCode()); // 创建线程池 ExecutorService pool = new ThreadPoolExecutor( 10, // corePoolSize: 核心线程数，即长期保持的线程数 20, // maximumPoolSize: 最大线程数 60L, // keepAliveTime: 空闲线程的存活时间 TimeUnit.SECONDS, // 时间单位 new LinkedBlockingQueue(100), // workQueue: 任务队列，容量为100 namedThreadFactory, // threadFactory: 线程工厂，用于给线程命名 new ThreadPoolExecutor.AbortPolicy() // rejectedExecutionHandler: 拒绝策略 ); return pool; 重构SeckillService，分离提交与执行@Servicepublic class SeckillService @Autowired private ExecutorService seckillExecutorService; // 1. 注入我们创建的线程池 // ... 其他属性保持不变 ... /** * 新的入口方法：负责接收请求并提交到线程池 * 这个方法会【立刻】返回，不会等待后台线程执行完毕 */ public String submitSeckillOrder(Long productId, Long userId) // 2. 创建一个任务（Runnable） Runnable task = () - // 在这个任务中，调用我们之前那个耗时的、带锁的真实秒杀逻辑 executeSeckill(productId, userId); ; // 3. 将任务提交给线程池 seckillExecutorService.submit(task); return 请求已接收，正在排队处理中，请稍后查看订单状态。; /** * 真实的秒杀执行逻辑，现在是一个私有方法 * 它会被后台线程池中的线程调用 * @param productId * @param userId */ private void executeSeckill(Long productId, Long userId) boolean acquired = false; try acquired = semaphore.tryAcquire(3, TimeUnit.SECONDS); if (!acquired) log.warn(线程 获取信号量许可超时, Thread.currentThread().getName()); return; // 获取不到许可，直接结束任务 // ... 省略了之前完整的、带 writeLock 和手动事务的业务逻辑 ... // 注意：因为这个方法现在没有返回值了，你需要通过日志来记录成功或失败 // 比如在 commit 后 log.info(订单创建成功...) // 在 rollback 后 log.error(订单创建失败...) catch (InterruptedException e) Thread.currentThread().interrupt(); log.error(线程 被中断, Thread.currentThread().getName()); finally if (acquired) semaphore.release(); 更新 SeckillController，调用新的“提交”方法。 压测结果与分析 JMeter设置与之前的版本相同，只执行写请求。 结果：有120个线程成功请求到了线程池，80个失败请求。没有任何的库存减少和新订单的建立，并且在日志中没有任何关于申请信号量许可的信息。 分析： 120个成功请求和80个失败请求：系统能够容纳的瞬时任务上限是20（正在执行）+100（排队等待）120个，而剩下的80个失败请求对应的是因为线程池已满而被拒绝。 没有库存减少和新订单的建立：120个被线程池接收的任务，没有一个成功完成数据库操作。 日志中没有见到任何申请信号量许可的信息：甚至有可能没有进入executeSeckill()方法。类似于“当第200个请求被拒绝后，所有200个请求都结束了” 原因：“守护线程”的提前退场 用户线程：通常创建的、执行核心任务的“前台线程”。JVM规则：只要还有一个用户线程没有执行完毕，JVM进程就必须等待，不能退出。 守护线程：特殊的“后台线程”，为其他线程服务。JVM规则：当程序中只剩下守护线程在运行时，JVM会认为所有核心工作已经全部完成，于是会退出并且终止所有仍在运行的守护线程。 由于某种原因，在seckillExecutorService中创建的工作线程，被设置为了守护线程。 改进 在创建线程时，明确设置为“用户线程”。 @Configurationpublic class ThreadPoolConfig @Bean public ExecutorService seckillExecutorService() ThreadFactory namedThreadFactory = r - Thread t = new Thread(r); // 【关键改动】将线程设置为非守护线程 t.setDaemon(false); t.setName(seckill-thread- + t.hashCode()); return t; ; // 创建线程池的其余代码保持不变 ExecutorService pool = new ThreadPoolExecutor( 10, 20, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue(100), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy() ); return pool; 在手动创建 Thread 对象后，调用了 t.setDaemon(false);。false 表示它是一个用户线程（非守护线程），这是 Java 线程的默认行为，但在这里我们明确地指定它，以覆盖任何可能的默认设置，确保万无一失。 结果：库存减少至0，新增订单数100，数据正常。日志显示正常。 单体应用的性能优化数据库原子化更新、引入内存售罄标记 使用“原子化SQL更新”替代Java锁，将检查库存和扣减库存合并为同一条SQL语句，并且引入内存售罄标记。数据库原子化更新利用了数据库的行锁来保证原子性，性能远高于在Java应用层加锁。引入内存售罄标记，直接拒绝已知的无效流量，保护了后端服务。 修改 ProductRepository.java @Repositorypublic interface ProductRepository extends JpaRepositoryProduct, Long /** * 【新增】原子化扣减库存的方法 * 使用 @Modifying 注解来告诉 Spring Data JPA 这是一个“修改”操作 * 使用 @Query 注解来定义我们的 JPQL 语句 * WHERE 子句中的 p.stock 0 是关键，它在数据库层面保证了不会超卖 * @param productId 商品ID * @return 返回受影响的行数，如果 0 表示更新成功，= 0 表示库存不足或商品不存在 */ @Modifying @Query(UPDATE Product p SET p.stock = p.stock - 1 WHERE p.id = :productId AND p.stock 0) int deductStock(@Param(productId) Long productId); 重构 SeckillService.java 的核心逻辑 @Servicepublic class SeckillService // ... 其他属性 ... // 【移除】不再需要写锁了！ // private final ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(true); // private final Lock writeLock = rwLock.writeLock(); // ... // 【新增】内存售罄标记 private volatile boolean isSoldOut = false; public String submitSeckillOrder(Long productId, Long userId) // 【优化】在所有逻辑之前，先检查内存标记 if (isSoldOut) return 商品已售罄（内存标记拦截）; // ... 之前的提交到线程池的逻辑保持不变 ... // ... private void executeSeckill(Long productId, Long userId) // ... Semaphore 的获取和释放逻辑保持不变 ... boolean acquired = false; try acquired = semaphore.tryAcquire(3, TimeUnit.SECONDS); if (!acquired) // ... return; // 【移除】不再需要 Thread.sleep() // Thread.sleep(1000); // 【重构】调用新的、无锁的数据库操作方法 executeDbOperationsWithoutLock(productId, userId); catch (InterruptedException e) // ... finally if (acquired) semaphore.release(); // 【重构】创建一个新的、无锁的数据库操作方法 private void executeDbOperationsWithoutLock(Long productId, Long userId) // 【移除】不再需要 writeLock.lock() DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); TransactionStatus status = transactionManager.getTransaction(def); try // 前置检查（重复下单等）依然可以保留 if (orderRepository.findByUserIdAndProductId(userId, productId) != null) throw new RuntimeException(您已秒杀过此商品，请勿重复下单); // 1. 【核心改动】直接调用原子更新方法扣减库存 int result = productRepository.deductStock(productId); // 2. 检查结果 if (result == 0) // 如果更新行数为0，说明库存不足 isSoldOut = true; // 【优化】设置内存售罄标记 throw new RuntimeException(商品已售罄); // 3. 如果扣减成功，才创建订单... transactionManager.commit(status); log.info(线程 秒杀成功，提交事务。, Thread.currentThread().getName()); catch (Exception e) transactionManager.rollback(status); log.error(线程 秒杀失败，回滚事务: , Thread.currentThread().getName(), e.getMessage()); // 【移除】不再需要 finally writeLock.unlock() 集成Spring Boot Actuator 修改 pom.xml 文件 在 标签内，添加 Actuator 的 starter 依赖： dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-actuator/artifactId/dependency 修改 srcmainresourcesapplication.properties 文件添加以下配置，来暴露所有的监控端点 (endpoints) 以供访问： # Spring Boot Actuator 配置# 暴露所有 Web 端点（在生产环境中应按需暴露，* 是为了开发方便）management.endpoints.web.exposure.include=*# (可选) 让 health 端点总是显示详细信息management.endpoint.health.show-details=always 学学八股ThreadPoolExecutor 线程池 核心作用 降低资源消耗：通过复用已创建的线程，避免了频繁创建和销毁线程的巨大开销。 提高响应速度：任务到达时，可以直接使用池中的线程执行，省去了创建线程的时间。 提高客观理性：可以对线程进行统一的分配、监控和调优，防止无限制的创建线程耗尽系统资源。 核心参数 corePoolSize ：核心线程数，线程池长期维持的线程数量，即使它们处于空闲状态。 maximumPoolSize ：最大线程数，线程池能够容纳的最大线程数量。当任务队列满了，且当前线程数小于最大线程数时，才会创建新线程。 KeepAliveTime：空闲线程存活时间，当线程池中的数量大于corePoolSize时，多余的空闲线程在等待新任务时能够存活的最长时间。 unit：时间单位 workQueue：任务队列，用于存放等待执行的任务的阻塞队列。 threadFactory： 线程工厂，用于创建新线程的工厂。 rejectedExecutionHandler：拒绝策略，当任务队列和线程池都满了，新任务到来时所采取的策略。 原子化SQL更新 核心思想：放弃在 Java 应用层使用锁（如 ReentrantLock）来保证“读-改-写”的原子性，而是将这个职责下推到数据库层面。 底层原理：数据库的 InnoDB 引擎 会对符合 WHERE 条件的行加上行锁 (Row Lock)，从而天然地保证了该操作的原子性。 Spring Boot Actuator 核心作用：通过一系列的HTTP端点，暴露应用的内部运行情况。 Actuator 是构建可观测性系统的第一步。通过它暴露的 metrics 端点，可以与 Prometheus (数据采集) 和 Grafana (数据可视化) 等工具链集成，搭建出专业的监控仪表盘，实时监控 JVM 状态、数据库连接池、线程池活跃度等关键指标。","tags":["Spring Boot","高并发","JUC"],"categories":["项目实战"]},{"title":"1-秒杀项目1.2-流量控制","path":"/2025/10/03/1-秒杀项目1.2-流量控制/","content":"场景升级：引入流量控制 在V1.1中，通过读写锁优化了系统的读性能，但留下了一个隐患，如果秒杀的“写”操作本身很耗时（比如需要调用外部API、复杂的数据库操作等），那么大量的写请求会在WriteLock.lock()处排起长队。这些排队的线程会持续占用着宝贵的服务器线程资源，当数量过多时，足以耗尽资源导致整个应用崩溃。 V1.2的核心目标就是，在进入核心业务逻辑之前，先进行流量控制，只允许有限数量的请求进入，从而保护系统不被瞬时流量冲垮。 代码改写 加入semaphore信号量 加入Thread.sleep(1000),模拟耗时的写操作。public String processSeckill(Long productId, Long userId) try // 带超时的尝试获取：在指定时间内获取不到，就放弃，避免无限等待 if (!semaphore.tryAcquire(3, TimeUnit.SECONDS)) return 服务器繁忙，请稍后再试！; // 这模拟了这样一种场景：比如，每个秒杀请求都需要先调用一个外部、 // 独立的、耗时1秒的API（如风控验证），这个API调用本身是可以并行的。 try Thread.sleep(1000); catch (InterruptedException e) Thread.currentThread().interrupt(); writeLock.lock(); try // ... 之前的完整手动事务逻辑 ... finally writeLock.unlock(); catch (InterruptedException e) // 线程在等待许可时被中断 Thread.currentThread().interrupt(); // 重新设置中断状态 return 请求被中断，请重试。; finally semaphore.release(); 最多10个线程可以同时获取到Semaphore许可。 这十个线程同时开始执行Thread.sleep(1000)，模拟10个并行的慢操作。 1秒后，这10个线程几乎同时结束sleep，然后去竞争writeLock。 WriteLock会确保他们一个一个地串行地完成数据库操作。 JMeter设置 保留写请求线程组 线程数：50 Ramp-up Period : 1（模拟瞬时的大流量） 循环次数：1 压测结果与分析 预期结果：吞吐量应该为10sec左右，即一秒钟内可以处理大约10个（由Semaphore信号量控制，而获取写锁之后的业务逻辑耗时极短）请求。 结果：吞吐量为19.8secJMeter聚合报告 分析：信号量泄漏-代码中的逻辑bug 当其中的某一个线程获取许可失败，会return 服务器繁忙，请稍后再试！，而无论try块中的代码是否正常结束，finally块中的代码都一定正常执行：semaphore.release();，也就是说，不管线程是否申请到了许可，都会执行finally块，即Semaphore内部的可用许可量可能会持续增加到10个以上。 使最后的结果显示——吞吐量：19.8sec。 改进：代码中的逻辑bug调整代码 修复：只有在成功获取到资源后，才能进入释放资源的finally块。 // 简化结构 public String processSeckill(...) if (semaphore.tryAcquire(...)) // 1. 先过“信号量”这道门（10个并发名额） try Thread.sleep(1000); // 2. 执行耗时1秒的【可并行】操作 writeLock.lock(); // 3. 再过“写锁”这道门（1个并发名额） try // 4. 执行耗时极短的【串行】数据库操作 finally writeLock.unlock(); finally semaphore.release(); 压测结果与分析 结果：吞吐量为11.1sec JMeter聚合报告 分析： 流程: 10个线程并行 sleep - 串行 writeLock 总耗时 (处理50个请求): 5010 批 * 1秒批 ≈ 5秒 吞吐量: 50 5s ≈ 10sec 当没有Semaphore时，吞吐量为20sec。 流程: 50个线程并行 sleep - 串行 writeLock 总耗时 (处理50个请求): 1秒 (并行sleep) + 50 * 数据库耗时 ≈ 2~3秒 吞吐量: 50 ~2.5s ≈ 20sec 证明了Semaphore流量控制的功能是生效的，它的作用不是提升性能，而是约束性能，防止过多的并发请求将系统资源耗尽，从而保证系统的稳定性。 学学八股Semaphore 是JUC包提供的一个并发流程控制工具，在内部维护了一组“许可”，线程在执行前必须先获取一个许可，执行完毕后再归还许可。当许可被全部分发完毕后，其他没有获取到许可的线程就必须等待，直到有线程释放许可。 核心思想：通过有限的许可，来控制同一时间能够访问特定资源或执行特定代码块的线程数量。 核心方法： acquire():阻塞式的获取一个许可。如果当前没有可用的许可，线程将进入休眠状态并排队等待，直到有其他线程调用release()。 release():释放一个许可。信号量内部的许可计数会+1，如果此时有等待的线程，队列中的第一个线程将被唤醒。 tryAcquire():非阻塞式的尝试获取许可。立即返回，成功为true，失败为false。 tryAcquire(long timeout,TimeUnit unit):在指定时间内获取许可，如果超时仍未获取到，则返回false。 底层原理：和ReentrantLock一样，Semaphore的底层也是基于AQS构建 state：AQS内部的int state 变量，在Semaphore中代表了当前可用的许可数量。 获取许可：对应AQS的共享模式获取，线程会通过CAS操作尝试将state-1，如果减1之后state的值仍然大于等于0，则获取成功。否则获取失败，线程会被打包成节点放入等待队列中并挂起、 释放许可：对应AQS的共享模式释放，线程会通过CAS操作将state+1，释放成功后，会唤醒等待队列中的后继线程。 关键特性与使用场景： Semaphore支持公平和非公平两种模式。 核心使用场景 流量控制限流：防止瞬时大量请求冲垮下游服务。 管理有限的资源池：比如控制同时访问数据库的连接数，或者控制同时使用某个昂贵计算资源的任务数。","tags":["Spring Boot","高并发","JUC"],"categories":["项目实战"]},{"title":"1-秒杀项目1.1-读写分离","path":"/2025/10/01/1-秒杀项目1.1-读写分离/","content":"一、最初的构想：引入读写锁 在秒杀开始前，有成千上万的用户疯狂刷新商品详情页，他们只是想看看库存还剩下多少，即进行读操作。在当前的实现下，大量的读请求也必须排队等待获取ReentrantLock，严重影响了用户体验。这是一个典型的“读多写少”的场景，所以引入读写锁。 改写代码 重构SeckillService，将业务逻辑拆分出两个核心方法： checkStock(): 专门用于查询库存，使用读锁。 /* * 新增方法，用于查询商品库存，专门用于处理读请求 * 使用读写锁中的读锁，允许并发读取，互不堵塞*/public Integer checkStock(Long productId) log.info(线程 尝试获取读锁..., Thread.currentThread().getName()); readLock.lock(); // 读操作上读锁 log.info(线程 成功获取到读锁, Thread.currentThread().getName()); try OptionalProduct productOpt = productRepository.findById(productId); if (!productOpt.isPresent()) throw new RuntimeException(商品不存在); log.info(线程 读取库存为: , Thread.currentThread().getName(), productOpt.get().getStock()); return productOpt.get().getStock(); finally log.info(线程 准备释放读锁., Thread.currentThread().getName()); readLock.unlock(); processSeckill(): 负责执行秒杀下单，使用写锁 public String processSeckill(Long productId, Long userId) log.info(线程 尝试获取写锁..., Thread.currentThread().getName()); writeLock.lock(); // 2. 秒杀操作上写锁，确保互斥 log.info(线程 成功获取到写锁, Thread.currentThread().getName()); // 3. 定义事务 DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); // 4. 开启事务 TransactionStatus status = transactionManager.getTransaction(def); try // ...所有业务逻辑，和之前一样 // 5. 【关键】在锁释放前，手动提交事务 transactionManager.commit(status); log.info(线程 秒杀成功，提交事务。, Thread.currentThread().getName()); return 秒杀成功！订单创建中...; catch (Exception e) // 6. 如果发生任何异常，手动回滚事务 transactionManager.rollback(status); log.error(线程 秒杀失败: , Thread.currentThread().getName(), e.getMessage()); // 将异常信息返回或记录日志 return e.getMessage(); finally // 7. 最后，释放锁 log.info(线程 准备释放写锁., Thread.currentThread().getName()); writeLock.unlock(); 同时，我也在 Controller 层为查询库存新增了一个 GET 方式的 API 接口。 JMeter设置 线程组一：读请求 线程数： 500。 Ramp-up: 1 循环次数: 10 在该线程组下，创建一个 HTTP 请求，指向读接口：GET /seckill/stock/1 线程组二：写请求 线程数： 200 Ramp-up: 1 循环次数: 1 在该线程组下，创建之前配置好的、带计数器的 HTTP 请求，指向写接口：POST /seckill/1?userId=$uniqueUserId同时启动压测：在 JMeter 中，同时运行多个线程组。 压测结果与分析 结果：读请求均为库存为0;写请求正常，数据库显示，库存数为0，订单数新建100。读请求 分析： 瞬时的大量写请求，在一个极端的时间窗口内将库存扣减完毕。读请求因为写锁被阻塞，等到它们能够被执行时，秒杀已经结束。 二、改进：并发测试场景设计调整JMeter设置 由于200个500个线程数太多，在日志中无法回看到最初的日志信息，所以修改线程数，便于观察。“写请求”线程组： 线程数: 20 Ramp-up Period: 从 1 改成 20。 作用： 这意味着 JMeter 会在20秒内“缓慢地”启动这200个线程，大约每1秒启动一个。这给了读请求在两个写请求之间“插进来”的机会。 循环次数 (Loop Count): 1 “读请求”线程组： 线程数: 50 Ramp-up Period: 也改成 20。 循环次数: 保持在 10 。 【关键】为两个线程组设置“调度器”： 在两个线程组的配置界面下方，找到并勾选 “调度器”。 在“持续时间”中，输入 30。 作用： 这会强制两个线程组都在运行30秒后自动停止。这能确保读写请求在同一个时间窗口内并发执行。 压测结果与分析 结果：读请求在日志中能够显示出库存数逐渐减少，写请求正常，且日志有如下模式，体现了读写锁“读共享、写独占”的理论：一次写 - 一大批读（读到的值都一样） - 又一次写 - 又一大批读（读到的新值都一样）…日志信息 学学八股ReentrantReadWriteLock 是一个读写锁的实现，在内部维护了一对关联的锁：一个共享的读锁和一个独占的写锁。在”读多写少“的场景下，如果使用ReentrantLock这种普通互斥锁，会因为大量的饿读操作也必须串行执行而导致性能低下。读写锁则允许多个读线程并发访问，极大提升了这类场景下的系统吞吐量。 读锁：如果当前没有任何线程持有写锁，那么任意数量的线程都可以成功获取并持有读锁。即读-读共享。 写锁：只有在没有任何线程持有读锁或写锁的情况下，一个线程才有可能成功获取写锁。即写-写互斥，写-读互斥。 可能的问题 “写饥饿”问题： 在非公平、高并发读的场景下，如果读请求源源不断，写线程可能很难有机会获取到写锁，因为它总能看到有线程持有读锁。这就是所谓的“写饥饿”。使用公平锁是缓解这个问题的一种方式。 性能并非总是更优： ReentrantReadWriteLock 的内部机制比 ReentrantLock 复杂得多，因此在读写竞争不明显或者并发度不高的情况下，它的开销可能会比简单的互斥锁更大。不要盲目使用，只有在明确的“读多写少”且存在性能瓶颈的场景下，它才是最佳选择。","tags":["Spring Boot","高并发","JUC"],"categories":["项目实战"]},{"title":"1-秒杀项目1.0-丢失更新和锁失效","path":"/2025/09/25/1-秒杀项目1.0-丢失更新和锁失效/","content":"一、项目概述 项目名称：高并发-秒杀系统（1.0 单体应用原型） 项目目标：从零开始设计并实现一个功能完备的秒-杀业务原型，旨在深入理解高并发场景下常见的技术挑战，如数据一致性（超卖、重复下单）、性能瓶颈等，并通过多种技术手段进行分析和优化。 技术栈： 后端框架：Spring Boot 数据持久层：Spring Data JPA,Hibernate 数据库：MYSQL 构建工具：Maven 测试工具：JMeter 二、项目搭建1. 环境搭建和初始化 使用 Spring Initializr 快速搭建了项目骨架，并集成 Spring Web、Spring Data JPA、MySQL Driver 等核心依赖。 Spring Web:是构建Web应用程序的核心模块。内嵌Web服务器，提供Spring MVC框架，用于HTTP报文处理能力。负责监听网络接口，接受所有外来的HTTP请求，然后根据请求的URL和方法，精准的转接给后台相应的Controller去处理。Spring Data JPA：是一个用来极大简化数据库访问的框架。可以自动化SQL，进行对象-关系映射（ORM），并进行简化的自定义查询。 在 application.properties 中完成了数据库连接池的基础配置。 2. 核心业务 设计核心数据表 商品表CREATE TABLE `product` (`id` BIGINT NOT NULL AUTO_INCREMENT COMMENT 商品ID,`name` VARCHAR(100) NOT NULL COMMENT 商品名称,`title` VARCHAR(255) NOT NULL COMMENT 商品标题,`image` VARCHAR(255) DEFAULT COMMENT 商品图片URL,`price` DECIMAL(10, 2) NOT NULL COMMENT 秒杀价格,`stock` INT NOT NULL COMMENT 库存数量,`start_time` DATETIME NOT NULL COMMENT 秒杀开始时间,`end_time` DATETIME NOT NULL COMMENT 秒杀结束时间,PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 订单表在订单表的设计中加入了 (user_id, product_id)的唯一索引，即每个用户只能下一单。CREATE TABLE `seckill_order` (`id` BIGINT NOT NULL AUTO_INCREMENT,`user_id` BIGINT NOT NULL COMMENT 用户ID,`product_id` BIGINT NOT NULL COMMENT 商品ID,`order_price` DECIMAL(10, 2) NOT NULL COMMENT 订单成交价格,`create_time` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 创建时间,PRIMARY KEY (`id`),UNIQUE KEY `idx_user_product` (`user_id`, `product_id`) COMMENT 唯一索引，防止同一用户重复秒杀同一商品) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 3. 基础功能实现 采用标准的MVC分层架构，创建Controller, Service, Repository 层。 Controller：作为应用的入口，直接处理外部的HTTP请求。Service：实现应用的核心业务逻辑。DAO：负责与数据库进行直接交互，完成数据的持久化操作。ModelEntity：数据的载体，定义了应用中的核心领域对象。 请求过程 实现秒杀接口的核心业务逻辑。 @Transactionalpublic String processSeckill(Long productId, Long userId) // 1. 从数据库读取 Product 对象到内存OptionalProduct productOpt = productRepository.findById(productId);Product product = productOpt.get(); // 假设此时读到的 stock 是 100// ... 其他检查 ...// 2. 在内存中计算新库存product.setStock(product.getStock() - 1); // 内存中的 stock 变为 99// 3. 将内存中的 Product 对象保存回数据库productRepository.save(product); // 4. 创建订单SeckillOrder order = new SeckillOrder();// ...orderRepository.save(order);return 秒杀成功！; 在初始版本中不加入任何的并发控制，后续会通过压力测试来暴露和分析最原始的并发问题。 三、并发问题的分析与演进1. 库存设置与JMeter设置 stock设置为100 JMeter 线程数：200 1秒内同时发出200个并发请求 计数器自增UserId 2. 实验结果 订单数增加了200个但是库存数只减少了20个 订单数 库存数 分析原因：事务和内存状态————Spring的@Transaction注解和JPA的工作机制 一级缓存：当第一个请求通过findById加载了ID为1的商品后，这个product对象会被放入当前事务的一级缓存中。 事务提交时才真正更新：productRepository.save(product)这个操作，并不是立即向数据库发送UPDATE语句，而要等到整个processSeckill方法执行完毕、事务准备提交时，才会生成并发送给数据库。 丢失的更新（stock80）：前十个线程有可能都加载到了还没有提交的product，即此时读到的stock依然是100，后面的九次更新覆盖了第一次更新，所以最终结果和只更新一次是完全一样的（stock变成了99）。每次都有一批线程在竞争，但最后只有一个线程的更新“活”到了最后，导致库存最终只减少了大约20次。 订单的正常建立（新增order数200）：orderRepository.save(order)这个操作，因为每个订单的主键都是自增的，并且（user_id,product_id）的组合也是唯一的，所以每一次订单的插入都能成功。 3. 改进第一次尝试-在 processSeckill 方法上加 synchronized 锁 预期结果:锁生效，200个线程变为串行处理，数据一致性得以保证。即库存数为0，订单数为100，但吞吐量降低，平均响应时间升高。 @Transactionalpublic synchronized String processSeckill(Long productId, Long userId) // 1. 从数据库读取 Product 对象到内存OptionalProduct productOpt = productRepository.findById(productId);Product product = productOpt.get(); // 假设此时读到的 stock 是 100// ... 其他检查 ...// 2. 在内存中计算新库存product.setStock(product.getStock() - 1); // 内存中的 stock 变为 99// 3. 将内存中的 Product 对象保存回数据库productRepository.save(product); // 4. 创建订单SeckillOrder order = new SeckillOrder();// ...orderRepository.save(order);return 秒杀成功！; 结果：数据依然错误，订单数为200，库存数为79,而吞吐量和平均响应时间没有发生明显变化。 分析：@Transaction 与 synchronized 的冲突 当给一个方法加上@Transaction注解时，Spring为了能够控制事务的开启、提交和回滚，并不会让你直接调用这个方法，相反，Spring会在运行时创建一个该类的代理对象proxy。 事务先生效：即代理对象的同名方法会被触发，代理对象会先开启一个事务 synchronized被绕过：它是Java原生关键字，作用于对象实例的锁，但Spring的代理机制在调用目标方法时，可能会导致锁机制失效，因为代理方法本身没有synchronized，调用父类（本身SeckillService）的方法时，锁的上下文可能已经丢失或不准确。即，Spring的AOP代理与Java原生的锁关键字之间存在冲突，代理绕过了锁，导致synchronized锁机制未生效。 第二次尝试-在事务内使用ReentrantLock 预期结果:锁生效，200个线程变为串行处理，数据一致性得以保证。即库存数为0，订单数为100，但吞吐量降低，平均响应时间升高。 @Transactionalpublic String processSeckill(Long productId, Long userId) // 1. 事务由代理对象在这里开启 // 2. 在方法开始时手动加锁 lock.lock(); try // 所有业务逻辑都放在 try 块中 // 其他检查 product.setStock(product.getStock() - 1); productRepository.save(product); SeckillOrder order = new SeckillOrder(); // ... orderRepository.save(order); return 秒杀成功！订单创建中...; finally // 3. 【至关重要】在 finally 块中解锁，确保即使发生异常也能释放锁 lock.unlock(); // 4. 事务由代理对象在这里提交 显示控制：lock.lock()是代码逻辑的一部分，在代理调用了实际方法之后，业务逻辑执行之前被调用。任何线程进入这个方法后，都必须先获取到这个锁才能继续执行。 安全释放：使用try…finally结构，确保无论业务逻辑是否成功，锁最终都会被释放，避免了“死锁”的风险。 结果：数据依然错误，订单数为200，库存数为79,而吞吐量和平均响应时间没有发生明显变化。 分析：锁的范围 VS 事务的范围 锁释放在前，事务提交在后，所以当线程A解锁后，UPDATE语句还没有提交进入数据库，而此时线程B立即取锁进入了方法，此时B读取到的库存数还是旧值。重演丢失更新问题。 第三次尝试-ReentrantLock + 手动事务 预期结果:锁生效，200个线程变为串行处理，数据一致性得以保证。即库存数为0，订单数为100，但吞吐量降低，平均响应时间升高。 解决方案：将事务控制移入锁内 放弃@Transaction注解，因为这个注解无法精细控制提交时机，改用最经典、最原始的手动事务管理。 使用PlatformTransactionManager 来手动控制事务的开始、提交和回滚。将整个生命周期包裹在锁内。@Autowiredprivate PlatformTransactionManager transactionManager;private final Lock lock = new ReentrantLock();public String processSeckill(Long productId, Long userId) // 1. 上锁 lock.lock(); DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); // 2. 开启事务 TransactionStatus status = transactionManager.getTransaction(def); try // ...所有业务逻辑，和之前一样 // 3. 【关键】在锁释放前，手动提交事务 transactionManager.commit(status); return 秒杀成功！订单创建中...; catch (Exception e) // 如果发生任何异常，手动回滚事务 transactionManager.rollback(status); // 将异常信息返回或记录日志 return e.getMessage(); finally // 4. 最后，释放锁 lock.unlock(); 结果:数据正确，库存为0，订单数为100，吞吐量没有下降，甚至比没有并发控制的1.0 版本还要高。 分析: 在高并发场景下，无序的并发混乱，有时远比有序的串行执行要慢。下表为初始版本和三次尝试版本的压测数据。 Label 样本 平均值 中位数 90% 百分位 95% 百分位 99% 百分位 最小值 最大值 异常 % 吞吐量 接收 KBsec 发送 KBsec 1.0秒杀系统 200 740 810 1044 1078 1083 254 1084 0.00% 95.92 18.27 20.51 2.0秒杀系统_添加关键字synchronized 200 578 598 744 763 767 79 831 0.00% 113.38 21.59 24.24 2.0秒杀系统_手动添加锁ReentrantLock 200 638 663 819 837 879 237 891 0.00% 105.76 20.14 22.62 2.0秒杀系统_不使用@Transaction手动加锁 200 905 1024 1148 1160 1175 203 1178 0.00% 100.45 18.25 21.48 无锁版虽然看似并行，但造成了数据库层面大量的行锁竞争、唯一键冲突错误、事务回滚，这些“无效”的数据库操作成为了真正的性能瓶颈。而加锁后的版本，虽然在应用层是串行的，但它保护了数据库，向数据库发送的是一连串干净、有效的请求，避免了数据库的内部冲突和错误处理开销，因此整体系统的有效吞吐量反而更高。 学学八股@Transaction注解 一个请求的生命周期 Controller接受请求，调用Service方法，但此时Service引用的是Spring的代理对象，而不是原始实例。代理对象的方法被触发，检查到方法上有@Transaction注解，代理对象向事务管理器（platformTransactionManager）请求开启一个新的事务。从数据库连接池中获取一个数据库连接，向MySQL服务器发送指令。此时一个数据库事务的“上下文”已经建立，但还没有任何实际的业务SQL被执行。在开启事务后，代理对象才会调用原始实例的方法，开始执行业务逻辑。但需要注意的是，这个阶段中是没有发生任何数据库操作的，只是告诉JPA的持久化上下文，标记了该对象，后续需要“留意”。 所有代码都执行完毕后，到达return语句，准备将结果返回。此时代理对象接收到真实方法的返回值，因为没有捕获到任何异常，代理对象判断这次业务执行是成功的，通知事务管理器可以提交事务了。事务管理器执行数据库同步，在真正COMMIT之前，JPA会执行一次Flush，生成SQL语句，发送到MYSQL服务器并执行，直到COMMIT被成功执行了，这次更新才被永久地鞋屋数据库磁盘。 代理对象将你方法的返回值传递给Controller，Controller再将其封装成HTTP响应返回给用户。 锁-初步 Synchronized：Keyword、JVM内置的同步原语，简单、隐式的加锁和解锁机制。 使用方法：修饰实例方法、修饰静态方法、修饰代码块。 实现依赖于每个Java对象头部的Mark Word和JVM内部的Monitor对象监视器（当线程尝试获取锁时，JVM会执行Monitorenter字节码指令，尝试获得对象Monitor所有权。释放锁时即执行monitorexit）。 锁升级机制：偏向锁—轻量级锁(当有第二个线程竞争时升级，竞争的线程通过自旋和CAS来尝试获取锁，不进入阻塞状态)—重量级锁（竞争加剧，自旋失败，升级，未获取到锁的线程会被阻塞，由内核进行调度，性能开销最大） ReentrantLock：是JUC工具包的核心成员，显式加锁和解锁机制。 使用方法：标准的使用范式 // 1. 在类中声明一个 Lock 实例private final ReentrantLock lock = new ReentrantLock(); public void someMethod() // 2. 在 try...finally 结构中进行加锁和解锁lock.lock(); // 获取锁try // 3. 保护的同步代码 finally // 4. 必须在 finally 块中释放锁lock.unlock(); 实现依赖于JUC的核心框架AQS，所有获取锁失败的线程，会被封装成节点放入一个CLH虚拟双向队列中进行排队等待。当锁被释放时，会从队列头部唤醒下一个等待的线程。整个过程都在用户态完成，避免了频繁的内核态切换。 AQS 内部通过一个 volatile 的 int 类型的 state 变量来表示同步状态（0表示未锁定，0表示已锁定），并使用 CAS 操作来原子性地修改这个 state 值。 功能丰富：等待可中断（等待锁的线程可被中断）、可实现公平锁（按线程请求的顺序获取锁）、可实现非公平锁（允许插队、吞吐量更高）、可尝试获取锁（可在指定时间内尝试获取锁，失败则返回）、可绑定多个条件（可分组唤醒等待的线程，实现更精细的线程通信） 选择问题：在绝大多数情况下，当并发冲突不激烈、同步逻辑简单时，优先选择Synchronized关键字，在特定的场景下，比如需要使用Synchronized不具备的高级功能时，或者是在我的秒杀项目中，需要将事务提交的完整过程都包裹在锁内，即手动控制锁时。","tags":["Spring Boot","高并发","JUC"],"categories":["项目实战"]},{"title":"论文阅读-A Survey on Long-Video Storytelling Generation:Architectures, Consistency, and Cinematic Quality","path":"/2025/09/12/论文阅读-1/","content":"一、论文内容 详细调研了32篇关于视频生成的论文，以确定决定AIGC视频生成质量的关键架构组件和训练策略。 1. 长视频生成方法的架构分类 长视频生成方法的架构分类 1.1 关键帧生成+插帧 技术核心： 解耦“内容”与“运动”。 阶段一：关键帧生成 技术： 使用强大的文本到图像模型 (如 Stable Diffusion, DALL-E) 或 低频采样的文本到视频模型，生成在时间上稀疏但内容上关键的画面。这些帧定义了场景的主要布局、主体和语义。此阶段专注于空间域的质量和语义准确性。 阶段二：帧插值运动生成 技术： 使用视频帧插值模型或运动填充模型。这些模型通常是轻量的，专注于学习两个帧之间的光流或潜在运动表示，以生成中间帧。此阶段专注于时间域的连贯性和平滑性。 优： 突破了生成长视频的长度限制；可利用最先进的文生图模型保证画面质量。 劣： 流程串行，总生成时间变长；两个阶段若使用独立模型，可能导致风格、外观不一致；插值错误会引入不自然的运动。 1.2 分块生成与拼接 技术核心： 分治，将长视频分解为可并行处理的独立短片段。 将长序列划分为多个不重叠的时间块。每个块由一个共享权重的视频生成模型独立生成。所有块生成后，在时间维度上进行拼接。 优： 大幅降低峰值显存占用，是生成长视频最实用的方法之一；天然支持并行生成，加快速度。 劣： 块间一致性仍是核心挑战，即便采用高级训练技巧，也难以达到端到端模型的完美流畅度。 1.3 潜在空间高压缩 技术核心： 降维，在高度压缩的潜在空间中操作，极大减少处理序列的Token数量。 编码：使用如VAE、VQ-VAE或VQ-GAN的编码器，将图像视频帧压缩到一个高度抽象的潜在表示。压缩比可以非常高（例如，将256px图像压缩为32x32的潜在编码，空间上压缩8倍）。 在潜在空间中生成： 扩散或自回归过程不是在像素空间，而是在这个压缩后的潜在空间中进行。要处理的数据量减少了数十至数百倍。 解码： 最后通过解码器将潜在表示转换回像素空间。 优： 效率的革命性提升，使得在消费级GPU上运行视频生成成为可能。 劣： 压缩必然伴随信息损失。高压缩会丢失细节，导致纹理模糊、高频信息（如精细边缘、文字）失真，以及快速运动中的伪影。 1.4 端到端时空建模 技术核心： 统一建模，将时间视为一个统一的维度，用3D卷积注意力共同建模时空信息。 3D U-Net DiT： 模型 backbone 使用 3D U-Net DiT。patch不再是2D的图像块，而是3D的时空立方体。模型一次性看到一个小的时间片段，从而能够联合理解空间外观和时间运动。 位置编码： 使用3D RoPE等高级位置编码，同时编码空间位置和时间位置。 代表： Sora 的技术报告表明其属于此类范式。它通过将视频转换为时空patch的序列，然后用类似GPT的Transformer进行生成。 优： 理论上质量最高的方法。能产生最连贯、物理最合理的运动，因为它能直接对时空联合分布进行建模。 劣： 计算和内存开销巨大。序列长度是 帧数 × 高度 × 宽度，这限制了其直接生成的视频长度和分辨率。是“梦想架构”，但目前对算力要求极高。 1.5 自回归Token预测 技术核心：范式转换，将视频生成视为“下一个token预测”问题，统一文本和视频的生成范式。 Token化： 使用强大的视觉分词器（如MAGVIT-v2, VQ-GAN）将每帧图像转换为一系列离散的token。 序列建模： 将文本token和视频token拼接成一个长的多模态序列。 自回归生成： 使用一个Decoder-Only的大型Transformer（如GPT）来按顺序预测下一个视觉token。 代表： Google 的 VideoPoet 是典型代表。 优： 架构极其简洁统一；可轻松利用来自LLM的 scaling law 和优化技巧；理论上可生成无限长视频。 劣： 自回归生成速度慢（无法并行解码）；错误会累积；对分词器的质量依赖极高。 2. 长视频生成方法的关键架构组件 AIGC视频生成流程 输入处理层 Text-Visual Tower ： 负责理解和处理条件输入（文本、图像、音频）的组件集合 从“T5系列+CLIP”组合转向“多模态大语言模型 (MLLM)”。 旧范式 ： 使用 T5T5-XXLumT5 等强大文本编码器与 CLIP 结合。T5负责深度语义理解，CLIP负责图文对齐。 趋势： 使用 MLLM（如 LLaVA, Qwen2-VL）单一模型替代上述组合。MLLM不仅能理解复杂语义，还能更好地理解空间指令（如“左边的猫”），实现更精细的视觉-文本特征对齐，减少语义漂移。HunyuanVideo 是这一趋势的代表。 核心生成层 Backbone： 3D U-Net —– DiT —- MM-DiT —- Flux-MM-DiT Decoder-only Transformer LLM 像GPT那样的纯自回归Transformer，代表模型（如VideoPoet）将视频生成视为“下一个token预测”问题。 Positional Encodings： SinusoidalRoPE ——– 3DRoPE 输出优化层 Visual-Video Tower ： 负责将内部表示转换为最终视频的组件 SD 2D VAE ————– 3D VAE Video VAE 从Stable Diffusion继承的2D编码器 前沿模型专用，能更好地压缩和重建时间信息，生成更连贯的视频。 MAGVIT-v2: 视频Tokenize模型，用于自回归方案。 双VAE 架构成为新趋势。使用两个独立的编码器分别处理静态外观特征和时序动态特征。 解耦外观与运动，使模型学习更专注。显著降低训练成本（如Open-Sora 2.0降低5-10倍）。更好地保持多主体身份一致性（如VideoAlchemist）。 3. 前沿AIGC视频生成工具 AIGC视频生成工具-1 HunyuanVideo (腾讯)：使用 Flux-MM-DiT 架构。其最大特点是使用自研的 Hunyuan MLLM 作为文本编码器，在理解中文语境和复杂指令方面表现出色。也采用了3D VAE和3D RoPE。参数量13B，能生成720p的高清视频。 Sora (OpenAI)：尽管细节未完全公开，但已知其使用 Diffusion Transformer (DiT) 作为核心架构。它的一大革命性能力是支持可变分辨率、持续时间和宽高比的生成，这与之前固定尺寸的模型截然不同。能生成长达1分钟的1080p高清视频，具有惊人的长程连贯性和世界模拟能力（如物体符合物理规律运动）。 Stable Video Diffusion (SVD) (Stability AI)：目前最流行、应用最广的开源视频生成模型之一。它是Stable Diffusion的图像到视频专门化版本。基于3D U-Net架构，是一个图像到视频的模型，这意味着你需要先有一张图片，它才能生成一段视频。它采用了帧间插值技术来生成长视频。支持生成14或25帧的576x1024分辨率视频。虽然在绝对质量上不如Sora，但其生成速度和质量在开源模型中非常均衡。 AIGC视频生成工具-2 Veo 3 (Google DeepMind)：基于DiT架构，并集成了多种先进的编码技术和训练目标。它旨在生成高质量的1080p视频，并同样支持长视频生成。官方演示显示其能生成超过一分钟的高质量、连贯视频。它特别强调了对复杂文本指令的精确理解和 cinematic 质量。 Open-Sora ：复现Sora。旨在通过完全开源的方式，逐步实现与Sora类似的能力。采用了最先进的Flux-MM-DiT作为主干网络，并使用了双VAE设计（Hunyuan 3DVAE + 自编码器）来处理外观和运动。它代表了开源社区的顶尖技术水平。支持生成256p 到 768p 分辨率的视频，参数量达到11B。其目标是不断追赶闭源模型的性能。 AIGC视频生成工具-3 AnimateDiff：基于3D U-Net，它可以被注入到任何基于Stable Diffusion的图像模型中，从而让静态图像模型“动起来”。不直接决定分辨率，而是依赖于底层图像模型的能力。极大地扩展了现有图像模型的能力，用户可以使用自己喜欢的任何图像模型来创建视频，降低了视频生成的门槛。 VideoPoet (Google)：非扩散模型路径。它证明了自回归方案在视频生成上同样有效。使用纯Transformer架构（Decoder-Only LLM），将视频和音频都转换为离散的token，像生成文本一样生成视频。支持生成多种分辨率和长宽比的视频，并能完成视频风格化、修复等多种任务。提供了一种与扩散模型截然不同的技术思路，架构非常简洁统一，潜力巨大。 二、延伸学习深度学习基础都忘光了 1. backbone - 图像扩散模型 - 3D U-Net - CNN - DiT - Transformer2. VAE3. T5CLIPMLLM三、AIGC视频检测点现代视频生成模型的技术特点，恰恰决定了其输出结果的“指纹”和可检测的漏洞。 漏洞类别 技术根源 具体表现与取证线索 1. 物理不合理性 模型对复杂物理规律的理解不完全或近似错误。 • 光影不一致： 光源方向、物体阴影在帧间发生跳变或不匹配。 • 流体与碰撞异常： 水、火、烟雾的运动违反物理规律；物体碰撞后的运动轨迹不自然。 • 相机模型违背： 生成的相机运动（如晃动、变焦）与真实相机拍摄的动力学特征不符。 2. 压缩与重构伪影 高压缩VAE 导致的高频信息丢失和重建误差。 • 高频细节缺失： 极细的线条、远处文字、密集纹理出现模糊或混淆。 • 色带与色块： 在平滑的颜色渐变区域出现不自然的色带（Color Banding）。 • 运动模糊失真： 动态模糊效果在整个画面上不一致，或与运动速度不匹配。 3. 时空不一致性 模型在生成长序列时长程依赖建模失败。 • 帧间闪烁： 物体表面纹理、亮度或颜色出现高频闪烁（Flickering）。 • 物体突变： 物体或人物在序列中突然出现、消失或形态剧变。 • 身份漂移： 生成的人脸身份特征在视频中无法保持完全一致。 4. 模型指纹溯源 不同模型架构和训练数据留下的独特“风格”印记。 • VAE解码特征： 不同VAE解码器重建的图像在局部纹理、边缘处理方式上存在差异。 • 位置编码模式： 使用3D RoPE的模型与使用正弦编码的模型，其时空关联模式可能不同。 • 纹理风格： 模型训练数据集的偏向会导致生成内容具有特定的纹理或色彩风格。","tags":["thesis","academic"],"categories":["论文阅读"]},{"title":"建站要闻","path":"/2025/05/31/从零开始搭建个人博客/","content":"一、为什么要搭建个人博客？ 技术成长的记录工具 让输入变输出，提高思维表达 二、搭建流程1. 环境准备初始化博客项目环境准备和初始化博客比较简单，我当时参考这个文章，非常顺利。 https://blog.csdn.net/2401_83582688/article/details/144380760https://blog.csdn.net/2401_83582688/article/details/144380760 2. 更换主题可以在hexo主题页面选择自己喜欢的主题： https://hexo.io/themes/https://hexo.io/themes/ hexo的主题 我选择了第一眼就非常喜欢的stellar主题，这个主题有非常完整的文档说明，使用这个主题的博客也很多，所以大多数问题都可以通过文档和教程解决。 https://xaoxuu.com/wiki/stellarhttps://xaoxuu.com/wiki/stellar 3. 遇到的问题以及解决方法 部署域名在初始化博客和更换主题后，个人博客还是由本地服务器模拟的，即通过hexo s 命令启动，浏览器显示的URL为https://localhost:4000，所以后面进行了部署，关于部署，我参考了这位博主的文章： https://www.panoshu.top/blog/fbbe79ce/https://www.panoshu.top/blog/fbbe79ce/ 一开始选择的是hexo+GitHub Pages +vercel的方案，这个方案完全免费，上手部署起来也很顺利。但是由于在更新到GitHub时总是timeout，遂放弃这个方案，转而hexo+vercel，也是免费+顺利的。强烈推荐第二种方案！ 关于域名，只需要去合适的域名购买网站上购买一个域名，然后绑定到vercel的project上就可以。 页脚设计在原有主题的基础上参考教程加入了访客统计和运行天数统计。 https://blog.bxzdyg.cn/p/使用Hexo和Stellar搭建个人博客网站/https://blog.bxzdyg.cn/p/使用Hexo和Stellar搭建个人博客网站/ 字体更改字体。 https://blog.bxzdyg.cn/p/使用Hexo和Stellar搭建个人博客网站/https://blog.bxzdyg.cn/p/使用Hexo和Stellar搭建个人博客网站/","tags":["hexo","stellar","vercel"],"categories":["blog搭建"]},{"title":"explore","path":"/explore/index.html","content":"2025 年 10 月 1 日秒杀系统的第二篇博客，并且探索了博客的很多新玩法。2025 年 9 月 25 日发布秒杀系统的第一篇博客，希望可以坚持下去，一个新的开始！ O1 2025年的小目标：项目线、八股线、算法线推进到90% 剩下10%在研一下学期找实习之前（1月、2月）完成 正常 3% KR1 项目线 秒杀系统项目2V1.0 初始版本，无并发控制V1.1+ 结合JUC进行优化...初步计划，在项目2中融合agent内容。 正常 3% KR2 八股线 结合秒杀系统这个项目推进Java八股的学习 正常 1% KR3 算法线 数组/链表哈希表/字符串双指针法/栈与队列二叉树回溯算法贪心算法动态规划单调栈图论 正常 1% KR-4 科研线 AIGC视频检测系统（暂时课题）前沿论文阅读基础理论书 正常 1% KR-4 生活线 健康作息精神hobby 正常 10%"},{"title":"1-秒杀项目1.0-丢失更新和锁失效","path":"/wiki/Seckill/1-秒杀项目1.0-丢失更新和锁失效.html","content":"一、项目概述 项目名称：高并发-秒杀系统（1.0 单体应用原型） 项目目标：从零开始设计并实现一个功能完备的秒-杀业务原型，旨在深入理解高并发场景下常见的技术挑战，如数据一致性（超卖、重复下单）、性能瓶颈等，并通过多种技术手段进行分析和优化。 技术栈： 后端框架：Spring Boot 数据持久层：Spring Data JPA,Hibernate 数据库：MYSQL 构建工具：Maven 测试工具：JMeter 二、项目搭建1. 环境搭建和初始化 使用 Spring Initializr 快速搭建了项目骨架，并集成 Spring Web、Spring Data JPA、MySQL Driver 等核心依赖。 Spring Web:是构建Web应用程序的核心模块。内嵌Web服务器，提供Spring MVC框架，用于HTTP报文处理能力。负责监听网络接口，接受所有外来的HTTP请求，然后根据请求的URL和方法，精准的转接给后台相应的Controller去处理。Spring Data JPA：是一个用来极大简化数据库访问的框架。可以自动化SQL，进行对象-关系映射（ORM），并进行简化的自定义查询。 在 application.properties 中完成了数据库连接池的基础配置。 2. 核心业务 设计核心数据表 商品表CREATE TABLE `product` (`id` BIGINT NOT NULL AUTO_INCREMENT COMMENT 商品ID,`name` VARCHAR(100) NOT NULL COMMENT 商品名称,`title` VARCHAR(255) NOT NULL COMMENT 商品标题,`image` VARCHAR(255) DEFAULT COMMENT 商品图片URL,`price` DECIMAL(10, 2) NOT NULL COMMENT 秒杀价格,`stock` INT NOT NULL COMMENT 库存数量,`start_time` DATETIME NOT NULL COMMENT 秒杀开始时间,`end_time` DATETIME NOT NULL COMMENT 秒杀结束时间,PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 订单表在订单表的设计中加入了 (user_id, product_id)的唯一索引，即每个用户只能下一单。CREATE TABLE `seckill_order` (`id` BIGINT NOT NULL AUTO_INCREMENT,`user_id` BIGINT NOT NULL COMMENT 用户ID,`product_id` BIGINT NOT NULL COMMENT 商品ID,`order_price` DECIMAL(10, 2) NOT NULL COMMENT 订单成交价格,`create_time` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 创建时间,PRIMARY KEY (`id`),UNIQUE KEY `idx_user_product` (`user_id`, `product_id`) COMMENT 唯一索引，防止同一用户重复秒杀同一商品) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 3. 基础功能实现 采用标准的MVC分层架构，创建Controller, Service, Repository 层。 Controller：作为应用的入口，直接处理外部的HTTP请求。Service：实现应用的核心业务逻辑。DAO：负责与数据库进行直接交互，完成数据的持久化操作。ModelEntity：数据的载体，定义了应用中的核心领域对象。 请求过程 实现秒杀接口的核心业务逻辑。 @Transactionalpublic String processSeckill(Long productId, Long userId) // 1. 从数据库读取 Product 对象到内存OptionalProduct productOpt = productRepository.findById(productId);Product product = productOpt.get(); // 假设此时读到的 stock 是 100// ... 其他检查 ...// 2. 在内存中计算新库存product.setStock(product.getStock() - 1); // 内存中的 stock 变为 99// 3. 将内存中的 Product 对象保存回数据库productRepository.save(product); // 4. 创建订单SeckillOrder order = new SeckillOrder();// ...orderRepository.save(order);return 秒杀成功！; 在初始版本中不加入任何的并发控制，后续会通过压力测试来暴露和分析最原始的并发问题。 三、并发问题的分析与演进1. 库存设置与JMeter设置 stock设置为100 JMeter 线程数：200 1秒内同时发出200个并发请求 计数器自增UserId 2. 实验结果 订单数增加了200个但是库存数只减少了20个 订单数 库存数 分析原因：事务和内存状态————Spring的@Transaction注解和JPA的工作机制 一级缓存：当第一个请求通过findById加载了ID为1的商品后，这个product对象会被放入当前事务的一级缓存中。 事务提交时才真正更新：productRepository.save(product)这个操作，并不是立即向数据库发送UPDATE语句，而要等到整个processSeckill方法执行完毕、事务准备提交时，才会生成并发送给数据库。 丢失的更新（stock80）：前十个线程有可能都加载到了还没有提交的product，即此时读到的stock依然是100，后面的九次更新覆盖了第一次更新，所以最终结果和只更新一次是完全一样的（stock变成了99）。每次都有一批线程在竞争，但最后只有一个线程的更新“活”到了最后，导致库存最终只减少了大约20次。 订单的正常建立（新增order数200）：orderRepository.save(order)这个操作，因为每个订单的主键都是自增的，并且（user_id,product_id）的组合也是唯一的，所以每一次订单的插入都能成功。 3. 改进第一次尝试-在 processSeckill 方法上加 synchronized 锁 预期结果:锁生效，200个线程变为串行处理，数据一致性得以保证。即库存数为0，订单数为100，但吞吐量降低，平均响应时间升高。 @Transactionalpublic synchronized String processSeckill(Long productId, Long userId) // 1. 从数据库读取 Product 对象到内存OptionalProduct productOpt = productRepository.findById(productId);Product product = productOpt.get(); // 假设此时读到的 stock 是 100// ... 其他检查 ...// 2. 在内存中计算新库存product.setStock(product.getStock() - 1); // 内存中的 stock 变为 99// 3. 将内存中的 Product 对象保存回数据库productRepository.save(product); // 4. 创建订单SeckillOrder order = new SeckillOrder();// ...orderRepository.save(order);return 秒杀成功！; 结果：数据依然错误，订单数为200，库存数为79,而吞吐量和平均响应时间没有发生明显变化。 分析：@Transaction 与 synchronized 的冲突 当给一个方法加上@Transaction注解时，Spring为了能够控制事务的开启、提交和回滚，并不会让你直接调用这个方法，相反，Spring会在运行时创建一个该类的代理对象proxy。 事务先生效：即代理对象的同名方法会被触发，代理对象会先开启一个事务 synchronized被绕过：它是Java原生关键字，作用于对象实例的锁，但Spring的代理机制在调用目标方法时，可能会导致锁机制失效，因为代理方法本身没有synchronized，调用父类（本身SeckillService）的方法时，锁的上下文可能已经丢失或不准确。即，Spring的AOP代理与Java原生的锁关键字之间存在冲突，代理绕过了锁，导致synchronized锁机制未生效。 第二次尝试-在事务内使用ReentrantLock 预期结果:锁生效，200个线程变为串行处理，数据一致性得以保证。即库存数为0，订单数为100，但吞吐量降低，平均响应时间升高。 @Transactionalpublic String processSeckill(Long productId, Long userId) // 1. 事务由代理对象在这里开启 // 2. 在方法开始时手动加锁 lock.lock(); try // 所有业务逻辑都放在 try 块中 // 其他检查 product.setStock(product.getStock() - 1); productRepository.save(product); SeckillOrder order = new SeckillOrder(); // ... orderRepository.save(order); return 秒杀成功！订单创建中...; finally // 3. 【至关重要】在 finally 块中解锁，确保即使发生异常也能释放锁 lock.unlock(); // 4. 事务由代理对象在这里提交 显示控制：lock.lock()是代码逻辑的一部分，在代理调用了实际方法之后，业务逻辑执行之前被调用。任何线程进入这个方法后，都必须先获取到这个锁才能继续执行。 安全释放：使用try…finally结构，确保无论业务逻辑是否成功，锁最终都会被释放，避免了“死锁”的风险。 结果：数据依然错误，订单数为200，库存数为79,而吞吐量和平均响应时间没有发生明显变化。 分析：锁的范围 VS 事务的范围 锁释放在前，事务提交在后，所以当线程A解锁后，UPDATE语句还没有提交进入数据库，而此时线程B立即取锁进入了方法，此时B读取到的库存数还是旧值。重演丢失更新问题。 第三次尝试-ReentrantLock + 手动事务 预期结果:锁生效，200个线程变为串行处理，数据一致性得以保证。即库存数为0，订单数为100，但吞吐量降低，平均响应时间升高。 解决方案：将事务控制移入锁内 放弃@Transaction注解，因为这个注解无法精细控制提交时机，改用最经典、最原始的手动事务管理。 使用PlatformTransactionManager 来手动控制事务的开始、提交和回滚。将整个生命周期包裹在锁内。@Autowiredprivate PlatformTransactionManager transactionManager;private final Lock lock = new ReentrantLock();public String processSeckill(Long productId, Long userId) // 1. 上锁 lock.lock(); DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); // 2. 开启事务 TransactionStatus status = transactionManager.getTransaction(def); try // ...所有业务逻辑，和之前一样 // 3. 【关键】在锁释放前，手动提交事务 transactionManager.commit(status); return 秒杀成功！订单创建中...; catch (Exception e) // 如果发生任何异常，手动回滚事务 transactionManager.rollback(status); // 将异常信息返回或记录日志 return e.getMessage(); finally // 4. 最后，释放锁 lock.unlock(); 结果:数据正确，库存为0，订单数为100，吞吐量没有下降，甚至比没有并发控制的1.0 版本还要高。 分析: 在高并发场景下，无序的并发混乱，有时远比有序的串行执行要慢。下表为初始版本和三次尝试版本的压测数据。 Label 样本 平均值 中位数 90% 百分位 95% 百分位 99% 百分位 最小值 最大值 异常 % 吞吐量 接收 KBsec 发送 KBsec 1.0秒杀系统 200 740 810 1044 1078 1083 254 1084 0.00% 95.92 18.27 20.51 2.0秒杀系统_添加关键字synchronized 200 578 598 744 763 767 79 831 0.00% 113.38 21.59 24.24 2.0秒杀系统_手动添加锁ReentrantLock 200 638 663 819 837 879 237 891 0.00% 105.76 20.14 22.62 2.0秒杀系统_不使用@Transaction手动加锁 200 905 1024 1148 1160 1175 203 1178 0.00% 100.45 18.25 21.48 无锁版虽然看似并行，但造成了数据库层面大量的行锁竞争、唯一键冲突错误、事务回滚，这些“无效”的数据库操作成为了真正的性能瓶颈。而加锁后的版本，虽然在应用层是串行的，但它保护了数据库，向数据库发送的是一连串干净、有效的请求，避免了数据库的内部冲突和错误处理开销，因此整体系统的有效吞吐量反而更高。 学学八股@Transaction注解 一个请求的生命周期 Controller接受请求，调用Service方法，但此时Service引用的是Spring的代理对象，而不是原始实例。代理对象的方法被触发，检查到方法上有@Transaction注解，代理对象向事务管理器（platformTransactionManager）请求开启一个新的事务。从数据库连接池中获取一个数据库连接，向MySQL服务器发送指令。此时一个数据库事务的“上下文”已经建立，但还没有任何实际的业务SQL被执行。在开启事务后，代理对象才会调用原始实例的方法，开始执行业务逻辑。但需要注意的是，这个阶段中是没有发生任何数据库操作的，只是告诉JPA的持久化上下文，标记了该对象，后续需要“留意”。 所有代码都执行完毕后，到达return语句，准备将结果返回。此时代理对象接收到真实方法的返回值，因为没有捕获到任何异常，代理对象判断这次业务执行是成功的，通知事务管理器可以提交事务了。事务管理器执行数据库同步，在真正COMMIT之前，JPA会执行一次Flush，生成SQL语句，发送到MYSQL服务器并执行，直到COMMIT被成功执行了，这次更新才被永久地鞋屋数据库磁盘。 代理对象将你方法的返回值传递给Controller，Controller再将其封装成HTTP响应返回给用户。 锁-初步 Synchronized：Keyword、JVM内置的同步原语，简单、隐式的加锁和解锁机制。 使用方法：修饰实例方法、修饰静态方法、修饰代码块。 实现依赖于每个Java对象头部的Mark Word和JVM内部的Monitor对象监视器（当线程尝试获取锁时，JVM会执行Monitorenter字节码指令，尝试获得对象Monitor所有权。释放锁时即执行monitorexit）。 锁升级机制：偏向锁—轻量级锁(当有第二个线程竞争时升级，竞争的线程通过自旋和CAS来尝试获取锁，不进入阻塞状态)—重量级锁（竞争加剧，自旋失败，升级，未获取到锁的线程会被阻塞，由内核进行调度，性能开销最大） ReentrantLock：是JUC工具包的核心成员，显式加锁和解锁机制。 使用方法：标准的使用范式 // 1. 在类中声明一个 Lock 实例private final ReentrantLock lock = new ReentrantLock(); public void someMethod() // 2. 在 try...finally 结构中进行加锁和解锁lock.lock(); // 获取锁try // 3. 保护的同步代码 finally // 4. 必须在 finally 块中释放锁lock.unlock(); 实现依赖于JUC的核心框架AQS，所有获取锁失败的线程，会被封装成节点放入一个CLH虚拟双向队列中进行排队等待。当锁被释放时，会从队列头部唤醒下一个等待的线程。整个过程都在用户态完成，避免了频繁的内核态切换。 AQS 内部通过一个 volatile 的 int 类型的 state 变量来表示同步状态（0表示未锁定，0表示已锁定），并使用 CAS 操作来原子性地修改这个 state 值。 功能丰富：等待可中断（等待锁的线程可被中断）、可实现公平锁（按线程请求的顺序获取锁）、可实现非公平锁（允许插队、吞吐量更高）、可尝试获取锁（可在指定时间内尝试获取锁，失败则返回）、可绑定多个条件（可分组唤醒等待的线程，实现更精细的线程通信） 选择问题：在绝大多数情况下，当并发冲突不激烈、同步逻辑简单时，优先选择Synchronized关键字，在特定的场景下，比如需要使用Synchronized不具备的高级功能时，或者是在我的秒杀项目中，需要将事务提交的完整过程都包裹在锁内，即手动控制锁时。","tags":[null,null],"categories":[null]},{"title":"1-秒杀项目1.2-流量控制","path":"/wiki/Seckill/1-秒杀项目1.2-流量控制.html","content":"场景升级：引入流量控制 在V1.1中，通过读写锁优化了系统的读性能，但留下了一个隐患，如果秒杀的“写”操作本身很耗时（比如需要调用外部API、复杂的数据库操作等），那么大量的写请求会在WriteLock.lock()处排起长队。这些排队的线程会持续占用着宝贵的服务器线程资源，当数量过多时，足以耗尽资源导致整个应用崩溃。 V1.2的核心目标就是，在进入核心业务逻辑之前，先进行流量控制，只允许有限数量的请求进入，从而保护系统不被瞬时流量冲垮。 代码改写 加入semaphore信号量 加入Thread.sleep(1000),模拟耗时的写操作。public String processSeckill(Long productId, Long userId) try // 带超时的尝试获取：在指定时间内获取不到，就放弃，避免无限等待 if (!semaphore.tryAcquire(3, TimeUnit.SECONDS)) return 服务器繁忙，请稍后再试！; // 这模拟了这样一种场景：比如，每个秒杀请求都需要先调用一个外部、 // 独立的、耗时1秒的API（如风控验证），这个API调用本身是可以并行的。 try Thread.sleep(1000); catch (InterruptedException e) Thread.currentThread().interrupt(); writeLock.lock(); try // ... 之前的完整手动事务逻辑 ... finally writeLock.unlock(); catch (InterruptedException e) // 线程在等待许可时被中断 Thread.currentThread().interrupt(); // 重新设置中断状态 return 请求被中断，请重试。; finally semaphore.release(); 最多10个线程可以同时获取到Semaphore许可。 这十个线程同时开始执行Thread.sleep(1000)，模拟10个并行的慢操作。 1秒后，这10个线程几乎同时结束sleep，然后去竞争writeLock。 WriteLock会确保他们一个一个地串行地完成数据库操作。 JMeter设置 保留写请求线程组 线程数：50 Ramp-up Period : 1（模拟瞬时的大流量） 循环次数：1 压测结果与分析 预期结果：吞吐量应该为10sec左右，即一秒钟内可以处理大约10个（由Semaphore信号量控制，而获取写锁之后的业务逻辑耗时极短）请求。 结果：吞吐量为19.8secJMeter聚合报告 分析：信号量泄漏-代码中的逻辑bug 当其中的某一个线程获取许可失败，会return 服务器繁忙，请稍后再试！，而无论try块中的代码是否正常结束，finally块中的代码都一定正常执行：semaphore.release();，也就是说，不管线程是否申请到了许可，都会执行finally块，即Semaphore内部的可用许可量可能会持续增加到10个以上。 使最后的结果显示——吞吐量：19.8sec。 改进：代码中的逻辑bug调整代码 修复：只有在成功获取到资源后，才能进入释放资源的finally块。 // 简化结构 public String processSeckill(...) if (semaphore.tryAcquire(...)) // 1. 先过“信号量”这道门（10个并发名额） try Thread.sleep(1000); // 2. 执行耗时1秒的【可并行】操作 writeLock.lock(); // 3. 再过“写锁”这道门（1个并发名额） try // 4. 执行耗时极短的【串行】数据库操作 finally writeLock.unlock(); finally semaphore.release(); 压测结果与分析 结果：吞吐量为11.1sec JMeter聚合报告 分析： 流程: 10个线程并行 sleep - 串行 writeLock 总耗时 (处理50个请求): 5010 批 * 1秒批 ≈ 5秒 吞吐量: 50 5s ≈ 10sec 当没有Semaphore时，吞吐量为20sec。 流程: 50个线程并行 sleep - 串行 writeLock 总耗时 (处理50个请求): 1秒 (并行sleep) + 50 * 数据库耗时 ≈ 2~3秒 吞吐量: 50 ~2.5s ≈ 20sec 证明了Semaphore流量控制的功能是生效的，它的作用不是提升性能，而是约束性能，防止过多的并发请求将系统资源耗尽，从而保证系统的稳定性。 学学八股Semaphore 是JUC包提供的一个并发流程控制工具，在内部维护了一组“许可”，线程在执行前必须先获取一个许可，执行完毕后再归还许可。当许可被全部分发完毕后，其他没有获取到许可的线程就必须等待，直到有线程释放许可。 核心思想：通过有限的许可，来控制同一时间能够访问特定资源或执行特定代码块的线程数量。 核心方法： acquire():阻塞式的获取一个许可。如果当前没有可用的许可，线程将进入休眠状态并排队等待，直到有其他线程调用release()。 release():释放一个许可。信号量内部的许可计数会+1，如果此时有等待的线程，队列中的第一个线程将被唤醒。 tryAcquire():非阻塞式的尝试获取许可。立即返回，成功为true，失败为false。 tryAcquire(long timeout,TimeUnit unit):在指定时间内获取许可，如果超时仍未获取到，则返回false。 底层原理：和ReentrantLock一样，Semaphore的底层也是基于AQS构建 state：AQS内部的int state 变量，在Semaphore中代表了当前可用的许可数量。 获取许可：对应AQS的共享模式获取，线程会通过CAS操作尝试将state-1，如果减1之后state的值仍然大于等于0，则获取成功。否则获取失败，线程会被打包成节点放入等待队列中并挂起、 释放许可：对应AQS的共享模式释放，线程会通过CAS操作将state+1，释放成功后，会唤醒等待队列中的后继线程。 关键特性与使用场景： Semaphore支持公平和非公平两种模式。 核心使用场景 流量控制限流：防止瞬时大量请求冲垮下游服务。 管理有限的资源池：比如控制同时访问数据库的连接数，或者控制同时使用某个昂贵计算资源的任务数。","tags":[null,null,null],"categories":[null]},{"title":"1-秒杀项目1.1-读写分离","path":"/wiki/Seckill/1-秒杀项目1.1-读写分离.html","content":"一、最初的构想：引入读写锁 在秒杀开始前，有成千上万的用户疯狂刷新商品详情页，他们只是想看看库存还剩下多少，即进行读操作。在当前的实现下，大量的读请求也必须排队等待获取ReentrantLock，严重影响了用户体验。这是一个典型的“读多写少”的场景，所以引入读写锁。 改写代码 重构SeckillService，将业务逻辑拆分出两个核心方法： checkStock(): 专门用于查询库存，使用读锁。 /* * 新增方法，用于查询商品库存，专门用于处理读请求 * 使用读写锁中的读锁，允许并发读取，互不堵塞*/public Integer checkStock(Long productId) log.info(线程 尝试获取读锁..., Thread.currentThread().getName()); readLock.lock(); // 读操作上读锁 log.info(线程 成功获取到读锁, Thread.currentThread().getName()); try OptionalProduct productOpt = productRepository.findById(productId); if (!productOpt.isPresent()) throw new RuntimeException(商品不存在); log.info(线程 读取库存为: , Thread.currentThread().getName(), productOpt.get().getStock()); return productOpt.get().getStock(); finally log.info(线程 准备释放读锁., Thread.currentThread().getName()); readLock.unlock(); processSeckill(): 负责执行秒杀下单，使用写锁 public String processSeckill(Long productId, Long userId) log.info(线程 尝试获取写锁..., Thread.currentThread().getName()); writeLock.lock(); // 2. 秒杀操作上写锁，确保互斥 log.info(线程 成功获取到写锁, Thread.currentThread().getName()); // 3. 定义事务 DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); // 4. 开启事务 TransactionStatus status = transactionManager.getTransaction(def); try // ...所有业务逻辑，和之前一样 // 5. 【关键】在锁释放前，手动提交事务 transactionManager.commit(status); log.info(线程 秒杀成功，提交事务。, Thread.currentThread().getName()); return 秒杀成功！订单创建中...; catch (Exception e) // 6. 如果发生任何异常，手动回滚事务 transactionManager.rollback(status); log.error(线程 秒杀失败: , Thread.currentThread().getName(), e.getMessage()); // 将异常信息返回或记录日志 return e.getMessage(); finally // 7. 最后，释放锁 log.info(线程 准备释放写锁., Thread.currentThread().getName()); writeLock.unlock(); 同时，我也在 Controller 层为查询库存新增了一个 GET 方式的 API 接口。 JMeter设置 线程组一：读请求 线程数： 500。 Ramp-up: 1 循环次数: 10 在该线程组下，创建一个 HTTP 请求，指向读接口：GET /seckill/stock/1 线程组二：写请求 线程数： 200 Ramp-up: 1 循环次数: 1 在该线程组下，创建之前配置好的、带计数器的 HTTP 请求，指向写接口：POST /seckill/1?userId=$uniqueUserId同时启动压测：在 JMeter 中，同时运行多个线程组。 压测结果与分析 结果：读请求均为库存为0;写请求正常，数据库显示，库存数为0，订单数新建100。读请求 分析： 瞬时的大量写请求，在一个极端的时间窗口内将库存扣减完毕。读请求因为写锁被阻塞，等到它们能够被执行时，秒杀已经结束。 二、改进：并发测试场景设计调整JMeter设置 由于200个500个线程数太多，在日志中无法回看到最初的日志信息，所以修改线程数，便于观察。“写请求”线程组： 线程数: 20 Ramp-up Period: 从 1 改成 20。 作用： 这意味着 JMeter 会在20秒内“缓慢地”启动这200个线程，大约每1秒启动一个。这给了读请求在两个写请求之间“插进来”的机会。 循环次数 (Loop Count): 1 “读请求”线程组： 线程数: 50 Ramp-up Period: 也改成 20。 循环次数: 保持在 10 。 【关键】为两个线程组设置“调度器”： 在两个线程组的配置界面下方，找到并勾选 “调度器”。 在“持续时间”中，输入 30。 作用： 这会强制两个线程组都在运行30秒后自动停止。这能确保读写请求在同一个时间窗口内并发执行。 压测结果与分析 结果：读请求在日志中能够显示出库存数逐渐减少，写请求正常，且日志有如下模式，体现了读写锁“读共享、写独占”的理论：一次写 - 一大批读（读到的值都一样） - 又一次写 - 又一大批读（读到的新值都一样）…日志信息 学学八股ReentrantReadWriteLock 是一个读写锁的实现，在内部维护了一对关联的锁：一个共享的读锁和一个独占的写锁。在”读多写少“的场景下，如果使用ReentrantLock这种普通互斥锁，会因为大量的饿读操作也必须串行执行而导致性能低下。读写锁则允许多个读线程并发访问，极大提升了这类场景下的系统吞吐量。 读锁：如果当前没有任何线程持有写锁，那么任意数量的线程都可以成功获取并持有读锁。即读-读共享。 写锁：只有在没有任何线程持有读锁或写锁的情况下，一个线程才有可能成功获取写锁。即写-写互斥，写-读互斥。 可能的问题 “写饥饿”问题： 在非公平、高并发读的场景下，如果读请求源源不断，写线程可能很难有机会获取到写锁，因为它总能看到有线程持有读锁。这就是所谓的“写饥饿”。使用公平锁是缓解这个问题的一种方式。 性能并非总是更优： ReentrantReadWriteLock 的内部机制比 ReentrantLock 复杂得多，因此在读写竞争不明显或者并发度不高的情况下，它的开销可能会比简单的互斥锁更大。不要盲目使用，只有在明确的“读多写少”且存在性能瓶颈的场景下，它才是最佳选择。","tags":[null,null,null],"categories":[null]},{"title":"1-秒杀项目1.3-异步处理和优化","path":"/wiki/Seckill/1-秒杀项目1.3-异步处理和优化.html","content":"用户体验：引入异步处理 在V1.1和V1.2，通过读写锁和信号量，构建了一个数据相对正确，流量可控的秒杀系统。尽管后端相对稳定，但用户体验糟糕，同步阻塞的模式，意味着用户必须在浏览器前“转圈圈”，等待后端的耗时操作。 在V1.3中，实现异步化，将用户请求与后端耗时任务解耦，实现用户的及时响应。 代码改写 线程池，创建ThreadPoolConfig.javaimport org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.concurrent.*;@Configurationpublic class ThreadPoolConfig @Bean public ExecutorService seckillExecutorService() // 手动实现一个简单的 ThreadFactory ThreadFactory namedThreadFactory = r - new Thread(seckill-thread- + r.hashCode()); // 创建线程池 ExecutorService pool = new ThreadPoolExecutor( 10, // corePoolSize: 核心线程数，即长期保持的线程数 20, // maximumPoolSize: 最大线程数 60L, // keepAliveTime: 空闲线程的存活时间 TimeUnit.SECONDS, // 时间单位 new LinkedBlockingQueue(100), // workQueue: 任务队列，容量为100 namedThreadFactory, // threadFactory: 线程工厂，用于给线程命名 new ThreadPoolExecutor.AbortPolicy() // rejectedExecutionHandler: 拒绝策略 ); return pool; 重构SeckillService，分离提交与执行@Servicepublic class SeckillService @Autowired private ExecutorService seckillExecutorService; // 1. 注入我们创建的线程池 // ... 其他属性保持不变 ... /** * 新的入口方法：负责接收请求并提交到线程池 * 这个方法会【立刻】返回，不会等待后台线程执行完毕 */ public String submitSeckillOrder(Long productId, Long userId) // 2. 创建一个任务（Runnable） Runnable task = () - // 在这个任务中，调用我们之前那个耗时的、带锁的真实秒杀逻辑 executeSeckill(productId, userId); ; // 3. 将任务提交给线程池 seckillExecutorService.submit(task); return 请求已接收，正在排队处理中，请稍后查看订单状态。; /** * 真实的秒杀执行逻辑，现在是一个私有方法 * 它会被后台线程池中的线程调用 * @param productId * @param userId */ private void executeSeckill(Long productId, Long userId) boolean acquired = false; try acquired = semaphore.tryAcquire(3, TimeUnit.SECONDS); if (!acquired) log.warn(线程 获取信号量许可超时, Thread.currentThread().getName()); return; // 获取不到许可，直接结束任务 // ... 省略了之前完整的、带 writeLock 和手动事务的业务逻辑 ... // 注意：因为这个方法现在没有返回值了，你需要通过日志来记录成功或失败 // 比如在 commit 后 log.info(订单创建成功...) // 在 rollback 后 log.error(订单创建失败...) catch (InterruptedException e) Thread.currentThread().interrupt(); log.error(线程 被中断, Thread.currentThread().getName()); finally if (acquired) semaphore.release(); 更新 SeckillController，调用新的“提交”方法。 压测结果与分析 JMeter设置与之前的版本相同，只执行写请求。 结果：有120个线程成功请求到了线程池，80个失败请求。没有任何的库存减少和新订单的建立，并且在日志中没有任何关于申请信号量许可的信息。 分析： 120个成功请求和80个失败请求：系统能够容纳的瞬时任务上限是20（正在执行）+100（排队等待）120个，而剩下的80个失败请求对应的是因为线程池已满而被拒绝。 没有库存减少和新订单的建立：120个被线程池接收的任务，没有一个成功完成数据库操作。 日志中没有见到任何申请信号量许可的信息：甚至有可能没有进入executeSeckill()方法。类似于“当第200个请求被拒绝后，所有200个请求都结束了” 原因：“守护线程”的提前退场 用户线程：通常创建的、执行核心任务的“前台线程”。JVM规则：只要还有一个用户线程没有执行完毕，JVM进程就必须等待，不能退出。 守护线程：特殊的“后台线程”，为其他线程服务。JVM规则：当程序中只剩下守护线程在运行时，JVM会认为所有核心工作已经全部完成，于是会退出并且终止所有仍在运行的守护线程。 由于某种原因，在seckillExecutorService中创建的工作线程，被设置为了守护线程。 改进 在创建线程时，明确设置为“用户线程”。 @Configurationpublic class ThreadPoolConfig @Bean public ExecutorService seckillExecutorService() ThreadFactory namedThreadFactory = r - Thread t = new Thread(r); // 【关键改动】将线程设置为非守护线程 t.setDaemon(false); t.setName(seckill-thread- + t.hashCode()); return t; ; // 创建线程池的其余代码保持不变 ExecutorService pool = new ThreadPoolExecutor( 10, 20, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue(100), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy() ); return pool; 在手动创建 Thread 对象后，调用了 t.setDaemon(false);。false 表示它是一个用户线程（非守护线程），这是 Java 线程的默认行为，但在这里我们明确地指定它，以覆盖任何可能的默认设置，确保万无一失。 结果：库存减少至0，新增订单数100，数据正常。日志显示正常。 单体应用的性能优化数据库原子化更新、引入内存售罄标记 使用“原子化SQL更新”替代Java锁，将检查库存和扣减库存合并为同一条SQL语句，并且引入内存售罄标记。数据库原子化更新利用了数据库的行锁来保证原子性，性能远高于在Java应用层加锁。引入内存售罄标记，直接拒绝已知的无效流量，保护了后端服务。 修改 ProductRepository.java @Repositorypublic interface ProductRepository extends JpaRepositoryProduct, Long /** * 【新增】原子化扣减库存的方法 * 使用 @Modifying 注解来告诉 Spring Data JPA 这是一个“修改”操作 * 使用 @Query 注解来定义我们的 JPQL 语句 * WHERE 子句中的 p.stock 0 是关键，它在数据库层面保证了不会超卖 * @param productId 商品ID * @return 返回受影响的行数，如果 0 表示更新成功，= 0 表示库存不足或商品不存在 */ @Modifying @Query(UPDATE Product p SET p.stock = p.stock - 1 WHERE p.id = :productId AND p.stock 0) int deductStock(@Param(productId) Long productId); 重构 SeckillService.java 的核心逻辑 @Servicepublic class SeckillService // ... 其他属性 ... // 【移除】不再需要写锁了！ // private final ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(true); // private final Lock writeLock = rwLock.writeLock(); // ... // 【新增】内存售罄标记 private volatile boolean isSoldOut = false; public String submitSeckillOrder(Long productId, Long userId) // 【优化】在所有逻辑之前，先检查内存标记 if (isSoldOut) return 商品已售罄（内存标记拦截）; // ... 之前的提交到线程池的逻辑保持不变 ... // ... private void executeSeckill(Long productId, Long userId) // ... Semaphore 的获取和释放逻辑保持不变 ... boolean acquired = false; try acquired = semaphore.tryAcquire(3, TimeUnit.SECONDS); if (!acquired) // ... return; // 【移除】不再需要 Thread.sleep() // Thread.sleep(1000); // 【重构】调用新的、无锁的数据库操作方法 executeDbOperationsWithoutLock(productId, userId); catch (InterruptedException e) // ... finally if (acquired) semaphore.release(); // 【重构】创建一个新的、无锁的数据库操作方法 private void executeDbOperationsWithoutLock(Long productId, Long userId) // 【移除】不再需要 writeLock.lock() DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); TransactionStatus status = transactionManager.getTransaction(def); try // 前置检查（重复下单等）依然可以保留 if (orderRepository.findByUserIdAndProductId(userId, productId) != null) throw new RuntimeException(您已秒杀过此商品，请勿重复下单); // 1. 【核心改动】直接调用原子更新方法扣减库存 int result = productRepository.deductStock(productId); // 2. 检查结果 if (result == 0) // 如果更新行数为0，说明库存不足 isSoldOut = true; // 【优化】设置内存售罄标记 throw new RuntimeException(商品已售罄); // 3. 如果扣减成功，才创建订单... transactionManager.commit(status); log.info(线程 秒杀成功，提交事务。, Thread.currentThread().getName()); catch (Exception e) transactionManager.rollback(status); log.error(线程 秒杀失败，回滚事务: , Thread.currentThread().getName(), e.getMessage()); // 【移除】不再需要 finally writeLock.unlock() 集成Spring Boot Actuator 修改 pom.xml 文件 在 标签内，添加 Actuator 的 starter 依赖： dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-actuator/artifactId/dependency 修改 srcmainresourcesapplication.properties 文件添加以下配置，来暴露所有的监控端点 (endpoints) 以供访问： # Spring Boot Actuator 配置# 暴露所有 Web 端点（在生产环境中应按需暴露，* 是为了开发方便）management.endpoints.web.exposure.include=*# (可选) 让 health 端点总是显示详细信息management.endpoint.health.show-details=always 学学八股ThreadPoolExecutor 线程池 核心作用 降低资源消耗：通过复用已创建的线程，避免了频繁创建和销毁线程的巨大开销。 提高响应速度：任务到达时，可以直接使用池中的线程执行，省去了创建线程的时间。 提高客观理性：可以对线程进行统一的分配、监控和调优，防止无限制的创建线程耗尽系统资源。 核心参数 corePoolSize ：核心线程数，线程池长期维持的线程数量，即使它们处于空闲状态。 maximumPoolSize ：最大线程数，线程池能够容纳的最大线程数量。当任务队列满了，且当前线程数小于最大线程数时，才会创建新线程。 KeepAliveTime：空闲线程存活时间，当线程池中的数量大于corePoolSize时，多余的空闲线程在等待新任务时能够存活的最长时间。 unit：时间单位 workQueue：任务队列，用于存放等待执行的任务的阻塞队列。 threadFactory： 线程工厂，用于创建新线程的工厂。 rejectedExecutionHandler：拒绝策略，当任务队列和线程池都满了，新任务到来时所采取的策略。 原子化SQL更新 核心思想：放弃在 Java 应用层使用锁（如 ReentrantLock）来保证“读-改-写”的原子性，而是将这个职责下推到数据库层面。 底层原理：数据库的 InnoDB 引擎 会对符合 WHERE 条件的行加上行锁 (Row Lock)，从而天然地保证了该操作的原子性。 Spring Boot Actuator 核心作用：通过一系列的HTTP端点，暴露应用的内部运行情况。 Actuator 是构建可观测性系统的第一步。通过它暴露的 metrics 端点，可以与 Prometheus (数据采集) 和 Grafana (数据可视化) 等工具链集成，搭建出专业的监控仪表盘，实时监控 JVM 状态、数据库连接池、线程池活跃度等关键指标。","tags":[null,null,null],"categories":[null]},{"title":"1-秒杀项目2.0-Redis机制","path":"/wiki/Seckill/1-秒杀项目2.0-Redis机制.html","content":"突破限制：引入Redis机制当前系统V1.3 已经具备的功能： 异步处理：用户的点击会立刻得到响应。 流量控制：保护系统不会因过多线程而崩溃 原子化SQL：数据库操作精准无误 内存标记：售罄后能快速拒绝请求。 无法回避的“物理上限”： 用户体验的断崖式下跌：服务器可能在第一秒就收到了数万甚至数十万的 HTTP 请求。而应用内置的 Tomcat 服务器线程池（比如200个）会瞬间被打满。后续的所有请求，都会在操作系统的 TCP 连接队列中排队，最终大量超时。 99% 的用户刷新页面后，看到的是一个永远在“转圈圈”的加载动画，或是冰冷的 “503 Service Unavailable” 错误。 数据库是最终的性能瓶颈：数据库的磁盘IO、网络带宽、以及自身的处理能力成为了整个系统性能的天花板。 数据库通常是多个业务的共享资源。秒杀业务对数据库的极限压榨，会导致整个网站的其他核心功能全部瘫痪。普通用户无法登录、无法浏览其他商品、无法对购物车里的其他商品下单。为了一个秒杀活动，导致整个电商平台的交易系统停摆，这是任何公司都无法接受的巨大损失。 应用服务器是“单点故障”：应用运行在一个实例上，如果这个应用因为任何原因，比如JVM崩溃或服务器宕机，挂掉，那么整个秒杀服务就会彻底中断。 整个秒杀服务彻底消失，恢复时间未知。 无法水平扩展：所有基于Java内存的并发控制，在多实例部署时都会失效。 暴露了架构的僵化和脆弱 Redis能解决什么问题？ 解决了数据库雪崩和用户体验差的问题 把高频的库存读写、用户资格判断，从毫秒级的、基于磁盘的MYSQL，转移到了微秒级的、基于内存的Redis。 99%的读写流量由Redis抗住，每秒可以处理数万甚至数万次请求。 数据库只负责收尾工作，只有极少数成功抢到资格的用户，它们的订单信息才会异步的、平稳的写入数据库中。 解决了单点故障和无法水平扩展的问题 通过将所有需要共享的状态统一放在Redis中，本身的Spring Boot应用本身变成了“无状态”的。 环境准备与集成 在 Spring Boot 项目中成功引入并连接到 Redis 安装并运行Redis 在电脑上，使用docker在后台启动一个名为seckill-redis的Redis容器，并将其6379端口映射到电脑的6379端口。 docker run -d --name seckill-redis -p 6379:6379 redis 添加Maven依赖 在pom.xml文件中，添加新的依赖 dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-data-redis/artifactId/dependency 保存并让IDE重新加载依赖 配置application.properties 添加 Redis 的连接信息 # ================== Redis Configuration ==================spring.redis.host=localhostspring.redis.port=6379 验证连接 可以创建一个简单的测试类来验证应用启动时能否成功连接到Redis @Componentpublic class RedisConnectionTester implements CommandLineRunner @Autowired private StringRedisTemplate redisTemplate; @Override public void run(String... args) throws Exception try String result = redisTemplate.getConnectionFactory().getConnection().ping(); System.out.println(=========================================); System.out.println(Successfully connected to Redis. PING response: + result); System.out.println(=========================================); catch (Exception e) System.err.println(=========================================); System.err.println(Failed to connect to Redis: + e.getMessage()); System.err.println(=========================================); 启动 Spring Boot 应用。在控制台看到了 Successfully connected to Redis 的信息，表示第一阶段就成功。 数据预热与缓存“读”操作 将查询库存的流量从 MySQL 转移到 Redis。 创建数据预热Service 在秒杀开始之前，把数据从MYSQL加载到Redis。用启动时加载器来模拟。 创建RedisPreheatService.java @Servicepublic class RedisPreheatService implements CommandLineRunner public static final String STOCK_KEY = seckill:stock:; public static final String PRODUCT_KEY = seckill:product:; public static final String USER_SET_KEY = seckill:users:; @Autowired private ProductRepository productRepository; // 假设你已注入 @Autowired private RedisTemplateString, Object redisTemplate; // 应用启动后自动执行 @Override public void run(String... args) throws Exception // 假设我们秒杀的商品ID是 1 long productId = 1L; Product product = productRepository.findById(productId).orElse(null); if (product != null) // 1. 清理旧数据（为了可重复测试） redisTemplate.delete(STOCK_KEY + productId); redisTemplate.delete(USER_SET_KEY + productId); // 2. 加载库存到 Redis String redisTemplate.opsForValue().set(STOCK_KEY + productId, product.getStock()); System.out.println(=========================================); System.out.println(Product + productId + stock preheated to Redis: + product.getStock()); System.out.println(=========================================); 改造SeckillService的checkStock方法 直接从Redis读数据 // 在 SeckillService.java 中@Autowiredprivate RedisTemplateString, Object redisTemplate;public Integer checkStock(Long productId) String stockKey = RedisPreheatService.STOCK_KEY + productId; Object stockObj = redisTemplate.opsForValue().get(stockKey); return stockObj != null ? Integer.parseInt(stockObj.toString()) : -1; 核心逻辑迁移（Redis + Lua脚本） 将最关键的“判断资格扣减库存”操作，从Java层的锁+数据库，迁移到Redis的原子化Lua脚本。 创建Lua脚本文件 在 srcmainresources 目录下，创建一个新文件夹 scripts。 在 scripts 文件夹里，创建一个新文件 seckill.lua -- seckill.lua-- KEYS[1]: 库存的 key (e.g., seckill:stock:1)-- KEYS[2]: 已购买用户集合的 key (e.g., seckill:users:1)-- ARGV[1]: 当前请求的用户 ID-- 1. 判断用户是否重复购买if redis.call(sismember, KEYS[2], ARGV[1]) == 1 then return 2 -- 2 代表重复购买end-- 2. 获取库存local stock = tonumber(redis.call(get, KEYS[1]))if stock = 0 then return 1 -- 1 代表库存不足end-- 3. 扣减库存redis.call(decr, KEYS[1])-- 4. 记录购买用户redis.call(sadd, KEYS[2], ARGV[1])return 0 -- 0 代表秒杀成功 配置并加载Lua脚本 创建一个RedisConfig.java文件。用于管理与Redis相关的Bean。 @Configurationpublic class RedisConfig /** * 【新增】配置并创建 RedisTemplate Bean * @param connectionFactory Spring Boot 自动配置好的连接工厂 * @return RedisTemplate 实例 */ @Bean public RedisTemplateString, Object redisTemplate(RedisConnectionFactory connectionFactory) // 创建 RedisTemplate 对象 RedisTemplateString, Object template = new RedisTemplate(); // 设置连接工厂 template.setConnectionFactory(connectionFactory); // 创建 JSON 序列化工具 GenericJackson2JsonRedisSerializer jsonSerializer = new GenericJackson2JsonRedisSerializer(); // 设置 Key 的序列化方式为 String template.setKeySerializer(new StringRedisSerializer()); template.setHashKeySerializer(new StringRedisSerializer()); // 设置 Value 的序列化方式为 JSON template.setValueSerializer(jsonSerializer); template.setHashValueSerializer(jsonSerializer); // 使配置生效 template.afterPropertiesSet(); return template; @Bean public DefaultRedisScriptLong seckillScript() DefaultRedisScriptLong redisScript = new DefaultRedisScript(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(scripts/seckill.lua))); redisScript.setResultType(Long.class); return redisScript; 重构SeckillService的核心秒杀逻辑// 在 SeckillService.java 中@Autowiredprivate DefaultRedisScriptLong seckillScript;// 我们需要一个内存队列来存放成功秒杀的订单信息private final BlockingQueueSeckillOrder orderQueue = new LinkedBlockingQueue(1000);// 改造异步执行的后台任务private void executeSeckill(Long productId, Long userId) ListString keys = Arrays.asList( RedisPreheatService.STOCK_KEY + productId, RedisPreheatService.USER_SET_KEY + productId ); // 执行 Lua 脚本 Long result = redisTemplate.execute(seckillScript, keys, userId.toString()); if (result == 0) log.info(用户 秒杀成功！, userId); // 秒杀成功，生成订单信息并放入内存队列 // 此时订单尚未写入数据库 Product product = ... // 可以从缓存或数据库获取商品信息 SeckillOrder order = new SeckillOrder(); order.setProductId(productId); order.setUserId(userId); order.setOrderPrice(product.getPrice()); // 将订单放入队列 try orderQueue.put(order); catch (InterruptedException e) Thread.currentThread().interrupt(); else if (result == 1) log.warn(用户 秒杀失败：库存不足, userId); else if (result == 2) log.warn(用户 秒杀失败：重复下单, userId); else log.error(用户 秒杀异常, userId); 异步持久化 创建订单消费者Service 新建一个OrderConsumeService.java @Servicepublic class OrderConsumerService // ... 其他注入的属性 ... // 应用启动后，开启一个后台线程 @PostConstruct private void startConsumer() new Thread(() - while (true) try SeckillOrder order = seckillService.getOrderQueue().take(); // 2. 循环体内部现在只调用这个新的、带事务的方法 createOrderInDb(order); catch (InterruptedException e) Thread.currentThread().interrupt(); log.error(订单消费者线程被中断, e); break; catch (Exception e) // 捕获所有其他可能的异常，防止线程意外终止 log.error(处理订单时发生未知异常, e); ).start(); /** * 3. 【新增】一个公开的、带事务注解的方法，专门用于数据库操作 * @param order 从队列中取出的订单信息 */ @Transactional public void createOrderInDb(SeckillOrder order) log.info(正在创建订单并扣减MySQL库存: , order); // 将所有数据库操作都放在这个方法里 orderRepository.save(order); int result = productRepository.deductStock(order.getProductId()); if (result == 0) // 这是一个补偿逻辑，理论上在Redis阶段已经保证了库存充足 // 但为了数据最终一致性，如果MySQL库存扣减失败，应抛出异常让事务回滚 throw new RuntimeException(MySQL as stock deduction failed for order: + order); log.info(数据库订单创建成功); 在 SeckillService 中为 orderQueue 提供一个 getter 方法。 JMeter压测结果分析与改进结果分析 结果：日志显示：处理订单时发生未知异常；数据库信息显示：订单正常创建，但是库存数没有减少；存在TransactionRequiredException报错。 分析： 订单正常创建：说明 orderRepository.save(order) 这行代码执行成功了，并且它的结果被提交到了数据库。 库存数没有减少：说明 productRepository.deductStock(…) 这行代码没有成功，或者它的结果被回滚了。 存在TransactionRequiredException报错：deductStock() 在执行时，没有找到一个正在运行的事务。 即，orderRepository.save() 在一个事务里成功了（或者在没有事务的情况下自动提交了），而紧接着的 deductStock() 却发现自己不在任何事务里。但是这两个方法在同一个被@Transactional注解的方法里。所以真正的原因应该是，方法上的@Transactional注解没有生效。因为这个方法是通过this关键字进行的方法自调用，无法触发AOP代理。当startConsumer方法在 while 循环里调用 createOrderInDb(order) 时，它实际上是在调用 this.createOrderInDb(order)，绕过了AOP代理，所以无人发现@Transactional注解，事务没有被开启。 改进 注入服务自身，通过代理对象来调用方法。 修改OrderConsumerService.java @Servicepublic class OrderConsumerService // ... 其他注入的属性 ... @Autowired private SeckillService seckillService; // 2. 注入自己（代理对象） // 使用 @Lazy 是为了解决循环依赖的潜在问题 @Autowired @Lazy private OrderConsumerService self; // 应用启动后，开启一个后台线程 @PostConstruct private void startConsumer() new Thread(() - while (true) try SeckillOrder order = seckillService.getOrderQueue().take(); // 3. 【关键改动】通过 self 代理对象来调用事务方法 self.createOrderInDb(order); catch (InterruptedException e) // ... catch (Exception e) // ... ).start(); /** * 这个方法保持不变，但现在它能被正确地代理了 */ @Transactional public void createOrderInDb(SeckillOrder order) // ... 之前的数据库操作逻辑完全不变 ... log.info(正在创建订单并扣减MySQL库存: , order); orderRepository.save(order); int result = productRepository.deductStock(order.getProductId()); if (result == 0) throw new RuntimeException(MySQL stock deduction failed for order: + order); log.info(数据库订单创建成功); @Autowired private OrderConsumerService self; 注入的 self 变量，不是 this 对象，而是 Spring 创建的、包含了事务处理逻辑的代理对象。 当调用 self.createOrderInDb(order) 时，请求就从startConsumer发到了AOP代理那里。 AOP代理会正常地开启事务，然后再让真实对象去执行数据库操作。这样，@Transactional 就重新恢复了它的作用。 结果：数据库信息显示正常，库存正确减少，订单正确建立。 学学八股Redis Redis是一个开源的、基于内存的、key-value结构的高性能数据库。 基于内存：是Redis高性能的根本原因。所有数据都存储在内存中，读写速度极快，远超基于磁盘的数据库。 key-value：数据存储方式非常简单，像一个巨大的HashMap，通过一个唯一的Key来存取一个Value。 不仅仅是缓存：除了被用于缓存外，也被广泛运用于数据库、消息队列等。 核心原理（为什么快） 纯内存操作：所有的操作都在内存中完成，完全避免了磁盘IO这个最耗时的环节。 单线程模型：Redis的核心网络模型和命令处理是由一个单线程来完成的。无线程切换开销、无锁竞争、IO多路复用。 Redis的原子性与Lua脚本 Redis的单个命令是原子性的，但是多个命令组合在一起，就不是原子性的。 但Redis允许将一段Lua脚本作为一个整体发送给服务器执行，Redis会保证这个脚本在执行期间不会被任何其他命令打断，从而实现了多个命令的原子性组合。 Redis的持久化机制 RDB：在指定的时间间隔内，将内存中的数据快照完整的写入到磁盘上的一个二进制文件中。恢复速度快，文件紧凑。但如果Redis在两次快照之间崩溃，会损失一部分数据。 AOF：将每一条接受到的写命令，以追加的方式写入到一个日志文件中，恢复时，重新执行一遍文件中的所有写命令。数据的安全性更高（最多只丢失1秒的数据），单文件体积大，恢复速度相对较慢。 Redis的缓存经典问题 缓存穿透：查询一个数据库中根本不存在的数据，缓存中自然也没有，导致每次请求都直接打到数据库上，失去了缓存的意义。 缓存空对象：如果数据库查询结果为空，依然在Redis中缓存一个特殊的空值，并设置一个较短的过期时间。 布隆过滤器：在Redis前再加一道屏障，用布隆过滤器快速判断请求的数据是否存在。 缓存击穿：一个热点Key在某个瞬间突然失效，导致海量的并发请求同时涌向这个Key，并全部穿透到数据库，导致数据库瞬时压力过大。 互斥锁：当缓存失效时，第一个查询请求获取一个互斥锁，然后去加载数据并回设缓存。其他线程则等待锁释放后，直接从缓存中获取数据。 热点数据永不过期：对极热点的数据设置逻辑过期，由后台线程异步更新。 缓存雪崩：大量的key在同一时间集中失效，导致瞬时大量的请求都穿透到数据库。 随机化过期时间：在基础过期时间上，增加一个随机值，避免集中失效。 高可用架构：通过Redis集群、限流降级等操作，保证即使缓存出现问题，数据库也不会被完全冲垮。","tags":[null,null,null],"categories":[null]}]